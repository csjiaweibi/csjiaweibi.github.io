---
title: '我所理解的数据库'
date: 2025-04-04
permalink: /posts/2025/04/blog-post-4/
tags:
  - cool posts
  - category1
  - category2
---


## MySQL


数据库连接池



## 语法

三大范式
- **第一范式**：要求将列尽可能最小的分割，希望消除某个列存储多个值的冗余的行为。
- **第二范式**：要求唯一的主键，且不存在对主键的部分依赖，希望消除表中存在冗余(多余)的列。
- **第三范式**：要求没有间接依赖于主键的列，即仍然是希望消除表中冗余的列。

语句执行顺序
1. **连接**：查询缓存、分析、预处理、优化、执行SQL语句。
2. **顺序**：
    - `FROM + JOIN`：确定查询的表
    - `WHERE`：进行条件过滤
    - `GROUP BY` 
    - 聚合函数（如COUNT(), SUM(), AVG(), MAX(), MIN()等）是在GROUP BY之后、HAVING之前处理的。
    - `HAVING`：进行分组
    - `SELECT`：选择指定的列 rank()计算 
    - `DISTINCT`：进行去重
    - `ORDER BY`：排序
    - `LIMIT/OFFSET`：限制返回的行数

连接
    笛卡尔积
        INNER JOIN（内连接,或等值连接）：获取两个表中字段匹配关系的记录。
        LEFT JOIN（左连接）：获取左表所有记录，即使右表没有对应匹配的记录。
        RIGHT JOIN（右连接）： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。

条件操作符包括：=, <>, >, <, >=, <=, LIKE, IN, BETWEEN, AND, OR, NOT

正则表达
%%

## 架构
服务器
    所有的内置函数以及跨存储引擎的功能都在服务层实现
    连接器
        建立连接 管理连接 校验身份

    查询缓存
        查询缓存是否存在

    解析器解析
        语法分析
        构建语法树
        方便读取表名  字段 语句类型

    执行sql
        预处理阶段
            检查表或者字段是否存在

        优化阶段
            决定使用什么索引
            制定成本最小的查询方案

        执行阶段
            从存储引擎读取记录，返回给客户端
            主键索引查询
            全表扫描
            索引下推


## 存储引擎

存储结构：
表空间由段（segment）、区（extent）、页（page）、行（row）组成





常用存储引擎
    InnoDB：支持事务和行级锁，支持崩溃恢复和多版本并发控制（MVCC），适合高并发和数据一致性要求高的场景。
    MyISAM：不支持事务，适合读操作频繁的应用，具有较快的读取性能，表级锁和支持全文索引。不太适合高兵发  但是性能强
    MEMORY：数据存储在内存中，访问速度极快，但数据在重启后会丢失。临时存放数据 不支持持久化
    ARCHIVE：用于存储大量的历史数据，支持数据压缩，但不支持更新和删除。CSV：以 CSV 格式存储数据，适合简单的数据交换和轻量级存储。

InnoDB数据页结构
每个页面16KB减去页头和页尾的开销（约200字节）用于存储实际数据 
B+树的每一个指针指向一页  按照主键建立索引
前两层存储索引数据 第三层保存实际数据

**BufferPool**

读操作通过buffer pool提高效率，写操作通过changebuffer来提高效率


**RedoLogBuffer**






## 日志系统
MySQL 通过日志系统保证数据的持久性和一致性。主要的日志包括：
重做日志（Redo Log）：
    InnoDB 使用重做日志来记录对数据页的修改，以确保事务的持久性。

撤销日志（Undo Log）：
    用于实现事务的回滚，支持 MVCC（多版本并发控制），确保读操作不被写操作阻塞。

二进制日志（Binary Log）：
    记录所有更改数据的事件，用于数据恢复和复制。
    MySQL 的 Binlog（Binary Log，二进制日志）是记录所有对数据库执行更改操作（如 INSERT、UPDATE 和 DELETE）的日志文件。在 MySQL 中，Binlog 的主要作用有数据恢复、主从复制、数据审计等。
    以下是 Binlog 的核心功能和常见应用场景。
        数据恢复（Data Recovery）场景：Binlog 可以用于数据恢复，特别是在因误操作或数据丢失时，通过 Binlog 恢复到特定时间点的状态。
        方法：增量备份：将 Binlog 与定期全量备份结合，可以实现增量备份。假设定期备份数据库后，生成的 Binlog 包含从上次备份至今的所有更改日志，那么可以通过 Binlog 进行增量恢复。
        时间点恢复：在误操作发生后，通过 Binlog 恢复到误操作之前的状态。例如，恢复到特定时间点或某个事务执行之前。
        步骤：查找误操作的时间或事务 ID，使用 mysqlbinlog 命令读取 Binlog 文件。截取在误操作之前的 Binlog 内容，重新执行这些操作以恢复数据。


## 事务
一致性  避免草台班子
ACID
原子性  通过undolog实现。
    undo log 实现  
    用于实现事务的回滚，支持 MVCC（多版本并发控制），确保读操作不被写操作阻塞。 

一致性    通过undolog、redolog、隔离性共同实现。
    异常处理

隔离性    通过加锁（当前读）&MVCC（快照读）实现。
    MVCC  与 linux相关
        针对快照读(普通 select 语句)，是通过 MVCC方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。
            快照读 读取历史版本 不加锁

        针对当前读(select .. for update 等语句)，是通过 next-keylock(记录锁+间隙锁)方式解决了幻读，因为当执行 select .. for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。
            读取最新版本 加锁

        多版本并发控制机制
            每个事务看到的都是符合其真实时刻的数据版本

        实现方式
            为每条记录维护版本链表去实现事务隔离性  避免脏读和不可重复读的问题


    事务隔离级别
        读未提交   一个事务还没提交时，它做的变更就能被别的事务看到。
            脏读  读取到了其他事务没有提交的数据
            幻读
            不可重复读

        读已提交     一个事务提交之后，它做的变更才会被其他事务看到。
            不可重复读  同一事务 两次读取数据的结果不一致
            幻读  同一事务两次读取同一范围内的数据集结果不一致
            基于 MVCC 实现：这两个隔离级别同样主要依赖于 MVCC 来实现。在 READ-COMMITTED 下，每次读取都会看到最新的已提交数据，而在 READ-UNCOMMITTED 下，甚至可以看到未提交的数据（脏读）。

        可重复读  一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。这是MySQL InnoDB 引擎的默认隔离级别；
            设置隔离级别为可重复读（REPEATABLE READ）可以避免不可重复读，但可能无法防止幻读
                在数据库理论中，标准的SQL规范定义的Repeatable Read(可重复读)隔离级别是允许幻读发生的。但在实际实现中，不同数据库对RR隔离级别的处理方式不同，特别是MySQL的InnoDB引擎通过多版本并发控制(MVCC)和间隙锁(Gap Lock)机制解决了幻读问题。
                在快照读情况下，mysql通过mvcc来避免幻读。
                在当前读情况下，mysql通过X锁或next-key来避免其他事务修改:

            基于 MVCC 实现：在 REPEATABLE-READ 隔离级别下，MySQL 主要依赖于 MVCC 来实现一致性读。MVCC 通过维护多个数据版本，使得每个事务都能看到一个一致的数据视图，而不会受到其他事务的影响。
            当前读需要加锁：然而，在某些情况下，REPEATABLE-READ 也需要使用锁机制。例如，在进行当前读（如 SELECT ... FOR UPDATE 或 UPDATE 操作）时，为了防止幻读现象，MySQL 会使用加锁读来锁定相关行，确保数据的一致性和完整性。
                SELECT ... FOR UPDATE 是 SQL 中的一个语句，主要用于实现行级锁定机制。它的主要作用和特点如下：
                基本含义
                    这是一个加锁的 SELECT 语句
                    它会锁定查询结果集中的所有行，防止其他事务修改这些行
                    直到当前事务提交或回滚后，锁才会释放

                主要用途
                    悲观锁实现：在读取数据时就锁定，防止并发修改
                    避免丢失更新：确保在事务期间数据不会被其他事务更改
                    实现并发控制：在需要严格数据一致性的场景下使用


            非锁定读与锁定读：在 REPEATABLE-READ 下，普通的 SELECT 查询是不加锁的，称为非锁定读；而涉及更新、删除等操作的查询则需要加锁，称为锁定读。

        串行化 
            基于锁实现：在 SERIALIZABLE 隔离级别下，MySQL 使用表级锁或行级锁来确保事务的串行化执行。这意味着所有读操作都会被转换为加锁读（即使用 SELECT ... FOR UPDATE 或 SELECT ... LOCK IN SHARE MODE），从而防止其他事务对同一数据进行修改或读取，确保事务的完全隔离。
            影响：虽然 SERIALIZABLE 提供了最高的隔离性，但它也带来了最大的性能开销，因为所有的读写操作都需要等待锁的释放。



    持久性   通过redolog实现。
        redo log实现
        InnoDB 使用重做日志来记录对数据页的修改，以确保事务的持久性。


## mvcc
    mvcc的实现，基于undolog、版本链、readview。
在mysql存储的数据中，除了我们显式定义的字段，mysql会隐含的帮我们定义几个字段。
trx_id:事务id，每进行一次事务操作，就会自增1。
roll_pointer:回滚指针，用于找到上一个版本的数据，结合undolog进行回滚。
什么是readview呢？
    当我们用select读取数据时，这一时刻的数据会有很多个版本（例如上图有四个版本），但我们并不知道读取哪个版本，这时就靠readview来对我们进行读取版本的限制，通过readview我们才知道自己能够读取哪个版本。

在一个readview快照中主要包括以下这些字段：
对readview中的参数做一些解释
    m_ids：活跃的事务就是指还没有commit的事务。
    max_trx_id：例如m_ids中的事务id为（1，2，3），那么下一个应该分配的事务id就是4，max_trx_id就是4。
    creator_trx_id：执行select读这个操作的事务的id。

readview如何判断版本链中的哪个版本可用呢？（重点！）
    从上到下分别为（1）（2）（3）（4），依次进行解释
    trx_id表示要读取的事务id
    （1）如果要读取的事务id等于进行读操作的事务id，说明是我读取我自己创建的记录，那么为什么不可以呢。
    （2）如果要读取的事务id小于最小的活跃事务id，说明要读取的事务已经提交，那么可以读取。
    （3）max_trx_id表示生成readview时，分配给下一个事务的id，如果要读取的事务id大于max_trx_id，说明该id已经不在该readview版本链中了，故无法访问。
    （4）m_ids中存储的是活跃事务的id，如果要读取的事务id不在活跃列表，那么就可以读取，反之不行。

mvcc如何实现RC和RR的隔离级别
    RC的隔离级别下，每个快照读都会生成并获取最新的readview。
    RR的隔离级别下，只有在同一个事务的第一个快照读才会创建readview，之后的每次快照读都使用的同一个readview，所以每次的查询结果都是一样的。

幻读问题
    快照读：通过mvcc，解决了RR的隔离级别下幻读问题，因为每次使用的都是同一个readview。但是无法解决RC隔离级别下的幻读问题。
    当前读：通过next-key锁（行锁+gap锁），解决RR隔离级别下幻读问题。


如何实现可重复读?

日志
    原子性、持久性、一致性都是通过redo log 和 undo log 来完成的。
    undo
        平常我们在对数据进行增删改时，InnoDB 除了会记录 redo log，还会将更新的数据记录写进 undo log 中。当事务出现异常，执行失败的时候，就需要利用 undo log 中的信息将数据回滚到修改之前的版本。
        提供回滚（行里面有一个roll point指向undo log该行修改前的信息)保证原子性!- MVCC（undo log版本链）
        undo log: 记录的是逻辑日志,记录修改前的信息

    redo log 用来保证事务的持久性，undo log用来保证事务的原子性。
        redo log: 记录的是物理日志,记录事务中修改的信息

    Redo Log两部分
        一是内存中的重做日志缓冲(Redo Log Buffer)，该部分日志是易失性的；
        二是磁盘上的重做日志文件(Redo Log File)，该部分日志是持久的。

    redo  log的主要功能是用于数据库崩溃时的数据恢复。


## 索引
不建立索引的字段就要进行全表扫描（从叶子节点从左到右通过链表搜索）
索引有哪些类别?

覆盖索引（Covering Index）
    是数据库中的一个重要概念，主要用于优化查询性能。它指的是索引中包含了查询所需的所有列，从而使得查询可以完全通过索引来满足，而无需访问表中的数据。这种优化可以显著提高查询速度，因为读取索引的数据通常比读取表的数据要快得多。覆盖索引的工作原理当查询的 SELECT 语句中所涉及的列都包含在索引中时，数据库可以直接从索引中返回结果，而不需要查找实际的数据行。这意味着查询只需访问索引，而不必执行回表操作。

全文索引(Full-Text)
    主要是为了快速检索大文本数据中的关键字的信息。字段长度比较大时，如果创建普通索引，在进行like模糊查询时效率比较低，这时可以创建全文索引，基于倒排索引，类似于搜索引擎。MyISAM存储引擎支持全文索引，InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。
    专门用于文本内容的搜索
    支持关键词搜索和模糊匹配
    MySQL、PostgreSQL等支持

前缀索引
    在文本类型如BLOB、TEXT或者很长的VARCHAR列上创建索引时，可以使用前缀索引，数据量相比普通索引更小，可以指定索引列的长度，但是数值类型不能指定。
    ALTER TABLE table_name ADD KEY(column_name(prefix_length));

组合索引
    指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循最左前缀原则。
    主键索引、普通索引、唯一索引等都可以使用多个字段形成组合索引。例如，ALTER TABLE table_name ADD INDEX index_name ( column1, column2, column3 );


物理存储分类
    聚簇（主键）索引  物理存储按照索引排序  一个表只能有一个
        在InnoDB存储引擎中，主键自动成为聚簇索引；如果没有定义主键，会选择第一个唯一非空索引；如果还没有，InnoDB会创建一个隐藏的聚簇索引

    非聚簇索引    物理存储并不按照索引排序  允许多个
        回表查询    因为非聚集索引存储的是主键ID
        索引的叶子节点存储的是指向数据行的指针（InnoDB中存储的是主键值）
        先通过索引找到主键值，再通过主键值找到数据行（回表）

主键索引（PRIMARY KEY）会创建一个聚簇索引（Clustered Index），其底层是 B+ 树，数据行直接存储在叶子节点。
普通索引（INDEX idx_name）会创建一个非聚簇索引（Secondary Index），其叶子节点存储主键值，而不是完整行数据。

最左匹配原则  必须要遵守最左匹配原则才能利用到联合索引
最左匹配原则是数据库中使用复合索引（联合索引）时的一个重要规则。它指的是：在查询条件中，必须按照复合索引中字段的顺序，从最左边的字段开始使用，才能充分利用索引。如果跳过了某个字段，则后续字段无法使用索引。
例如，假设有一个复合索引 (A, B, C)：
查询条件包含 A 和 B 时，可以利用索引。
查询条件只包含 B 和 C 时，无法利用索引。
查询条件只包含 A 时，可以利用索引。

- 为什么需要满足最左匹配原则？
    要理解这一点，我们需要从 B+树的存储结构入手。B+树是一种多路平衡查找树，其节点中的键值是按照一定顺序排列的。复合索引的多个字段会组合成一个有序的键值序列，并存储在 B+树的节点中。
    (1)复合索引的存储方式
        复合索引 (A, B, C) 的存储方式类似于一个多维排序：首先按字段 A 排序；如果 A 相同，则按字段 B 排序；如果 A 和 B 都相同，则按字段 C 排序。

    (2)查询如何利用索引？
        B+树的查找过程是从根节点开始，逐步向下查找，直到找到符合条件的叶子节点。为了高效地利用索引，查询条件必须与索引的排序顺序一致。
        如果查询条件包含 A=1，可以直接定位到以 A=1 开头的所有记录。
        如果查询条件包含 A=1 AND B=2，可以进一步缩小范围，定位到以 (A=1, B=2) 开头的所有记录。
        如果查询条件只包含 B=2，由于 B+树的排序首先基于 A，因此无法直接定位到 B=2 的记录，只能进行全表扫描。



**B+树、B树和红黑树的特点及区别**
大量数据下的检索效率
- 考虑：数据存储位置、叶子节点结构、索引查找效率、树的高度、顺序访问效率、磁盘I/O效率、适用场景、平衡性、插入/删除操作、实现复杂度、空间利用率
第一个方面是数据存储位置。B+树将所有数据存储在叶子节点，非叶子节点只存储索引键；B树则将数据存储在叶子节点和非叶子节点中，所有节点都存储数据；而红黑树则在每个节点中都存储数据。
第二个方面是叶子节点结构。B+树通过链表连接叶子节点，这使得范围查询和顺序遍历非常高效；B树的叶子节点不一定通过链表连接，缺乏直接支持范围查询的结构；红黑树没有专门的叶子节点结构，所有节点通过指针连接。
第三个方面是索引查找效率。B+树的查找操作最终都在叶子节点完成，查找路径统一，效率较高；B树的查找操作可能在非叶子节点完成，查找路径不统一，效率稍低；红黑树的查找路径统一，时间复杂度为O(log n)，每次操作通过旋转和重新染色来保持平衡。
第四个方面是树的高度。B+树由于扇出较高（每个节点存储多个键），树的高度通常较低，查询效率较高；B树由于非叶子节点也存储数据，扇出较小，树的高度较高；红黑树作为二叉查找树，树的高度较高，每个节点最多有两个子节点，树的深度较大。
第五个方面是顺序访问效率。B+树通过链表连接叶子节点，支持高效的顺序访问，尤其在范围查询时表现出色；B树没有直接的顺序访问机制，顺序访问效率较低；红黑树也缺乏顺序访问机制，顺序遍历效率较低。
第六个方面是磁盘I/O效率。B+树由于非叶子节点只存储索引，扇出高，可以减少磁盘访问次数，因此磁盘I/O效率非常优秀；B树稍逊于B+树，因为非叶子节点也存储数据，导致扇出较小，磁盘访问次数略多；红黑树的磁盘I/O效率较差，因为树的高度较高，每次查找可能需要频繁访问磁盘。
第七个方面是适用场景。B+树常用于数据库索引、文件系统索引，适合大规模数据的存储和检索，尤其在需要高效范围查询时；B树适用于数据库索引和文件系统索引，但相比B+树，查找效率稍低；红黑树适用于内存中的数据结构，如Java中的TreeMap和TreeSet，适合存储符号表、集合、关联数组等内存数据。
第八个方面是平衡性。B+树将所有叶子节点置于同一层，平衡性非常好；B树平衡性较好，但查找路径不统一，效率稍逊；红黑树通过旋转和染色来保持平衡，查找路径统一，操作保持平衡。
第九个方面是插入/删除操作。B+树的插入和删除操作可能会引发节点分裂和合并，操作较复杂；B树的插入和删除操作也可能引发节点分裂和合并，操作较复杂；红黑树通过旋转和染色保持平衡，操作相对简单。
第十个方面是实现复杂度。B+树的实现较复杂，尤其是在处理链表结构和节点分裂/合并时；B树的实现也较复杂，涉及节点分裂/合并，但相对较为简单；红黑树的实现相对简单，通过旋转和染色来保持平衡。
第十一个方面是空间利用率。B+树的空间利用率较高，非叶子节点只存储索引，存储效率较好；B树的空间利用率较低，非叶子节点存储数据和索引，存储效率较低；红黑树的空间利用率较高，所有节点都存储数据，且由于树的平衡性，内存利用效率较好。

   

**索引失效**
一定失效
    查询条件中使用了函数或者表达式操作时
    使用了类型隐式转换
    使用了like 并且以 %开头时  索引会失效
        如果%出现在末尾 ，索引会生效

    查询条件使用了OR 且部分条件未命中索引时  索引失效
        例如，如果查询条件是 WHERE indexed_column = 'value1' OR non_indexed_column = 'value2'，即使 indexed_column 上有索引，但由于 non_indexed_column 没有索引，数据库可能会选择全表扫描，从而导致索引失效。

    查询中使用了 NOT 或 != 操作符
        这样的查询条件通常会导致数据库放弃使用索引，因为这类操作需要扫描大量数据来排除不符合条件的记录。

    查询中使用了复合索引但未遵循最左前缀原则
        例如，假设有一个复合索引 (A, B, C)，如果查询条件只包含 B 或 C，而没有包含 A，那么这个复合索引将无法被使用。只有从最左边的列开始，并按顺序使用索引列，才能有效利用复合索引。

    查询中使用了 IS NOT NULL 
        虽然 MySQL 支持对 IS NULL 使用索引，但在很多情况下，特别是 IS NOT NULL 的查询，数据库可能会选择全表扫描，从而导致索引失效。


不一定失效（存储引擎会根据实际情况选择是采用全表扫描还是继续走索引）
    in操作符 like 通配符  不等于
    between 都有可能导致失效  通配符 not in is null !=  <>  on 
    范围查找也有可能失效


索引如何优化
    明确查询性能
        查询执行所需的时间    
        对CPU  内存  和 I/0 的消耗
        查询返回的数据量

    计划任务  explain 关键字 分析SQL查询的执行计划，帮助优化查询性能
        关键字段  
            查询每个操作的id  
            查询 类型和表名 type table（如SIMPLE、SUBQUERY）
            连接类型,能使用的索引和实际索引  key
            必须检查的  row
            Extra：额外信息（如Using where、Using index）
                优化：根据输出信息调整索引、查询条件或表结构。
                    优化SQL
                    添加索引：根据key和type列优化索引
                    优化查询条件：减少rows扫描行数
                    避免全表扫描：确保type为INDEX或RANGE






## 锁
避免错误
用来控制对数据库操作的并发访问的重要机制
锁模式
    意向锁
        事务对表或者索引的意图
            表面事务想要在更细粒度上加锁


    插入意向锁
        事务向新表插入新行的意图

    排他锁
        FOR UPDATE 是MySQL的行级锁，用于防止并发修改
            转账操作：防止并发转账导致余额错误
            库存管理：防止超卖订票系统
            防止重复订票

        转账操作要使用事务和锁来保证数据安全，而查询操作要使用索引来提高性能。

    共享锁
        其他事务可以读 但不可以写

    乐观锁
    悲观锁
    快照读
    当前读
    行锁
        行级锁的类型主要有三类：
            Record Lock，记录锁，也就是仅仅把一条记录锁上；-
            Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；
                Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。




## 数据问题
单表数据超过500万行或者单表容量超过2GB 推荐分库分表   -阿里开发公约
数据倾斜
数据倾斜展开聊聊，数据倾斜的本质，热点数据处理
数据量太大
    分页
        深分页
            优化 
                子查询的条件下
                避免使用limit  导致扫描大量不必要的数据
                使用书签标记法  找到开始元素的位置  这样就不用每个表都去查了
                联表查询延迟关联	 join查询




数据迁移
    方便管理 降低成本


## 工具
        JDBC
            Java平台中用于连接和操作数据库的标准API。它提供了一套统一的接口，允许开发者通过Java代码与不同的数据库进行交互，而不必关心底层数据库的具体实现。
            JDBC主要用于执行SQL语句、查询和更新数据库中的数据。JDBC的核心功能包括：
                1. 连接数据库：通过DriverManager类管理和打开数据库连接。
                2. 执行SQL语句：通过Statement、PreparedStatement和CallableStatement对象来执行SQL查询、更新、存储过程等。
                3. 处理结果集：通过ResultSet对象来处理SQL查询返回的结果。
                4. 事务管理：可以通过JDBC控制事务的提交与回滚，确保数据的一致性和完整性。


        ORM
            SQLBuilder：SQL语句要非硬编码，通过某种链式调用构造器帮助我构建SQL语句。
            Scanner：从数据库返回的数据可以自动映射赋值到结构体中。


## 案例分析篇
        慢查询优化
            慢查询优化的关键在于启用慢查询日志并进行深入分析，这能帮助我们识别和优化那些执行效率低下的SQL语句。总体上是通过三个步骤来进行，先捕获低效SQL，然后使用工具进行分析，最后采用一些方法和原则进行优化，接下来我会进行详细讲述。
            首先，是捕获低效SQL，在此时我们需要确保慢查询日志已启用。通过设置全局变量slow_query_log为'ON'来开启此功能，并设定long_query_time参数以确定什么程度的查询延迟被视为“慢”。可以使用SHOW VARIABLES命令来检查这两个设置的状态，确保配置正确无误。
            接下来，我们要分析慢查询日志，这是找出问题根源的关键步骤。利用工具如mysqldumpslow可以帮助我们总结日志信息，比如按出现频率或总执行时间排序，从而聚焦于最需要关注的查询语句。
            对于每一个慢查询，我们可以使用EXPLAIN命令查看MySQL如何执行这些查询。EXPLAIN提供的输出能够揭示查询执行计划中的细节，例如是否进行了全表扫描（ALL），以及哪些索引被使用等。根据这些信息，我们可以做出更明智的决策来优化查询性能。
            最后是，采用一些方法和原则进行优化，常用的方法有4种。
                第一种是，建立和优化索引。合理的索引设计可以让查询更加高效，特别是对于经常出现在查询条件、连接条件、排序和分组操作中的字段。同时，删除不再需要的索引也能减少维护开销。
                第二种是，对查询本身进行优化，避免不必要的列选择，尽量减少数据传输量，并考虑使用批量或分页查询来处理大数据集。此外，尽量用JOIN替代子查询，因为JOIN通常具有更好的性能表现。
                第三种是，调整数据库和系统的配置参数，例如，适当增大InnoDB缓冲池大小、调整临时表的大小限制等，都可以带来显著的性能改进。
                第四种是，对于特别大的表，可以考虑采用水平切分或垂直切分策略，通过将数据分散到多个表或数据库实例中，进一步减轻单个实例的压力，改善整体查询性能。

            慢查询的解决方案
                解决MySQL慢查询问题的方案可以按照资源消耗从少到多的顺序排列，像金字塔一样逐步提升。以下是从资源消耗少到多的常见优化方式：
                (1)SQL优化
                    合理使用索引：确保查询字段使用了索引。对于WHERE、JOIN、ORDER BY、GROUP BY等操作的字段，应该创建相应的索引。

                (2)索引优化
                    创建复合索引：对于多个字段联合查询，创建复合索引（注意索引顺序）。
                    删除冗余索引：定期清理无用索引，减少索引维护的负担。
                    避免索引覆盖不必要的字段：有时候一个大字段（如TEXT或BLOB）放入索引会增加存储开销，应该避免。
                    更新统计信息：定期更新表的统计信息，帮助优化器选择更合适的执行计划。

                (3)数据库配置优化
                    调整缓存设置：增加innodb_buffer_pool_size，确保更多的数据能够缓存到内存中。调整query_cache_size，如果适用，启用查询缓存（对于更新频繁的应用不推荐）。
                    调整连接设置：如增加max_connections，但要注意数据库承载能力。
                    调整临时表大小：如果临时表经常写入磁盘，可以通过调整tmp_table_size和max_heap_table_size来避免此问题。
                    增加排序缓存：增加sort_buffer_size来提高ORDER BY和GROUP BY操作的效率。

                (4)架构优化
                    分库分表：对于单表数据量过大的情况，使用分库分表策略，将数据分散到不同的数据库或表中，减少每个查询的负载。
                    读写分离：通过主从复制，减少主库的查询压力，读请求分发到从库。
                    数据库集群：使用分布式数据库系统，解决单机性能瓶颈。

                (5)硬件升级
                    增加内存：通过增加内存，提高缓存命中率，减少磁盘IO。
                    更换更快的磁盘：使用SSD代替传统的硬盘，提升磁盘IO性能。
                    增加CPU处理能力：提升CPU性能，减少数据库查询的CPU瓶颈。



        连接池   druid
            mybatis中，使用了数据库 连接池技术，避免频繁的创建连接、销毁连接而带来的资源浪费。
            资源重用
            提升系统响应速度
            避免数据库连接遗漏
            产品要怎么样实现数据库连接池呢？
                官方(sun)提供了数据库连接池标准（javax.sql.DataSource接口）
                功能：获取连接 public Connection getConnection() throws SQLException;    第三方组织必须按照DataSource接口实现

            Hikari、Druid  （性能更优越）    Hikari（追光者） [默认的连接池]
             Druid（德鲁伊）Druid连接池是阿里巴巴开源的数据库连接池项目   德鲁伊功能强大，性能优秀，是Java语言最好的数据库连接池之一

        分库分表
        读写分离
        主从复制模型的区别、两阶段提交,区别



