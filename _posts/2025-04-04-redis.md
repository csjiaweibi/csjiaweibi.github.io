---
title: '我所理解的Redis'
date: 2025-04-04
permalink: /posts/2025/04/blog-post-4/
tags:
  - cool posts
  - category1
  - category2
---

redis    
## 数据结构
字符串
    缓存计数器
    它的特点是一个键对应一个值，且支持原子操作，比如递增（INCR）、递减（DECR）等，主要用于缓存简单的键值对数据，比如用户会话信息或计数器。
    缓存对象、常规计数、分布式锁、共享 session 信息等
    SDS(简单动态字符串)
        保存二进制数据
        SDS 获取字符串长度的时间复杂度是 0(1)。因为C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n);而 SDS 结构里用 len 属性记录了字符串长度，所以复杂度为 O(1)。
        Redis 的 SDS  API是安全的，拼接字符串不会造成缓冲区溢出。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。


列表
    它的特点是底层采用双向链表，插入和删除操作非常高效。另外，支持队列和栈的操作，比如先进先出（FIFO）或后进先出（LIFO）。常用于消息队列、任务调度等场景。
    消息队列  1.生产者需要自行实现全局唯一 ID;2.不能以消费组形式消费数据等。
    栈  文章列表
    双向链表或压缩列表实现的。
    如果列表的元素个数小于 512 个(默认值，可由 list-max-ziplist-entries 配置)，列表每个元素的值都小于 64 字节(默认值，可由 list-max-ziplist-value 配置)，Redis 会使用压缩列表作为 List 类型的底层数据结构
    如果列表的元素不满足上面的条件，Redis 会使用双向链表作为 List 类型的底层数据结构,但是
    在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表。
    redis中有序集合的实现采用了一种数据结构——跳跃表。跳跃表是有序单链表的一种改进，其查询、插入、删除也是O(logN)的时间复杂度。
    1.列表中的元素是有序的，可以通过索引下标获取某个元素霍某个某个范围内的元素列表
    2.列表中的元素可以是重复的

集合
    常用于去重、标签系统等场景。
    Set 类型:聚合计算(并集、交集、差集)场景，比如点赞、共同关注、抽奖活动等
    Set 类型的底层数据结构是由哈希表或整数集合实现的:
    如果集合中的元素都是整数且元素个数小于 512(默认值，set-maxintset-entries配置)个，Redis 会使用整数集合作为 Set 类型的底层数据结构
    如果集合中的元素不满足上面条件，则 Redis 使用哈希表作为 Set 类型的底层数据结构。
    Redis的Set是string类型的无序集合，我们不能通过索引获取元素。集合成员是唯一的，这就意味着集合中不能出现重复的数据。Redis中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。

哈希
    适合存储结构化数据，比如用户信息。它支持对单个字段的操作，比如 HGET 和 HSET。
    Hash 类型:缓存对象、购物车等。
    Hash 类型的底层数据结构是由压缩列表或哈希表实现的
    如果哈希类型元素个数小于 512 个(默认值，可由 hash-max-ziplist-entries 配置)，所有值小于 64 字节(默认值，可由 hash-max-ziplist-value 配置)的话，Redis 会使用压缩列表作为 Hash 类型的底层数据结构
    如果哈希类型元素不满足上面条件，Redis 会使用哈希表作为 Hash 类型的底层数据结构,在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了
    几乎所有的编程语言都提供了哈希（hash）结构，Redis中 hash 是一个string类型的field和value的映射表value={{field1,value1},{field2,value2}…}，可以将一个Hash表作为一个对象进行存储，表中存放对象的信息。

有序集合
    它也是一种集合，但它的每个元素都关联一个分数，元素按照分数排序。它的特点是在底层实现结合了跳表和哈希表，支持高效的范围查询。且元素唯一且有序，适合需要排序的场景，比如排行榜。还支持按分数范围获取元素，比如 ZRANGE 和 ZRANGEBYSCORE。
    排行榜
    在有序集合中保留了不能有重复成员的特性，但其中的成员是可以排序的，每一个元素都会关联一个double类型的分数（score）作为排序依据，score相同时按字典顺序排序。redis正是通过分数来为集合中的成员进行从小到大的排序。应用场景： 排行榜系统，成绩单，工资表
        排行榜：可以轻松实现用户积分排行榜，自动根据分数更新排名。
        实时评分：适用于社交应用中的点赞、评分等功能。
        任务调度：可以用作调度系统，按优先级处理任务。

    zset实现原理·Zset 类型:排序场景，比如排行榜、电话和姓名排序等
        跳表(Skip List)是一种基于链表的数据结构，它通过维护多层索引来加速查找操作。跳表的设计非常巧妙，提供了与平衡树相近的性能，但实现更为简单。
        基本结构
            跳表本质上是对有序链表的优化，由以下部分组成：
            底层链表：一个完整的有序链表，包含所有元素
            多层索引：每层索引都是对下层元素的抽取，形成了一系列稀疏程度不同的链表
            索引层级：从底向上，每层索引的节点数量大致是下一层的一半
            工作原理
            跳表的查找过程类似于电梯的运行：
            从最高层开始查找
            在当前层水平移动，直到找到大于或等于目标值的节点
            如果大于目标值，则下降一层继续查找
            重复上述过程直到找到目标或确定不存在

        核心特性
            时间复杂度：
                查找、插入、删除操作的平均和最坏时间复杂度都是O(log n)
                空间复杂度为O(n)

            概率平衡：
                跳表是一个概率数据结构，依靠随机化来保持平衡
                每个节点有约50%的概率出现在上一层索引中

            实现简单：
                相比红黑树、AVL树等平衡树结构，实现代码更简洁
                没有复杂的旋转或重平衡操作
    Zset 类型的底层数据结构是由压缩列表或跳表实现的:·如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用压缩列表作为Zset 类型的底层数据结构
    如果有序集合的元素不满足上面的条件，Redis 会使用跳表作为 Zset 类型的底层数据结构
    在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了Redis 的 ZSet（有序集合）是一种非常强大的数据结构，结合了集合和链表的特性。每个元素都关联一个分数（score），根据分数的值来排序，从而实现按分数的排序和访问。ZSet 在实现排行榜、评分系统、实时数据分析等场景中非常有用。
    Redis 的 ZSet（有序集合）是一种非常强大的数据结构，它结合了集合（Set）和排序列表（List）的特性。ZSet 允许对每个元素关联一个分数（score），并根据分数自动排序。下面将详细讨论 ZSet 的实现原理。

BitMap
    (2.2 版新增):二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等
    描述：位图是一种基于字符串的特殊数据结构，用于高效存储布尔值（0 和 1）。
    特点：每个位表示一个布尔值。支持高效的位操作。
    常用命令：
    SETBIT key offset value：设置指定偏移量的位值。
    GETBIT key offset：获取指定偏移量的位值。
    BITCOUNT key：统计位图中为 1 的位数。
    使用场景：
    用户签到记录（每天用 1 位表示是否签到）。
    统计在线用户数量。

HyperLogLog
    (2.8 版新增):海量数据基数统计的场景，比如百万级网页 UV 计数等;
    描述：HyperLogLog 是一种用于估算集合基数（唯一元素数量）的数据结构。
    特点：使用极小的内存空间进行基数统计。结果是近似值，误差率约为 0.81%。
    常用命令：
    PFADD key element：向 HyperLogLog 中添加元素。
    PFCOUNT key：获取基数估计值。
    PFMERGE destkey sourcekey：合并多个 HyperLogLog。
    使用场景：
    网站 UV（独立访客）统计。
    大规模数据的去重统计。

Stream
    (5.0 版新增):消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性:自动生成全局唯一消息ID，支持以消费组形式消费数据，
    描述：Streams 是 Redis 5.0 引入的一种数据结构，用于处理消息流。
    特点：消息是有序的，按时间戳排序。支持消费者组（Consumer Groups），允许多个消费者协作处理消息。
    常用命令：
    XADD key ID field value：向流中添加消息。
    XREAD key：读取消息。
    XGROUP CREATE key groupname ID：创建消费者组。
    XREADGROUP GROUP groupname consumer COUNT count：从消费者组中读取消息。
    使用场景：
    消息队列（如 Kafka 的轻量级替代方案）。
    日志收集和分析。

GEO
    (3.2 版新增):存储地理位置信息的场景，比如滴滴叫车;


# 底层架构


## 单机
部署简单；
成本低，无备用节点；
高性能，单机不需要同步数据，数据天然一致性。

可靠性保证不是很好，单节点有宕机的风险。
单机高性能受限于 CPU 的处理能力，Redis 是单线程的。

　　单机 Redis 能够承载的 QPS（每秒查询速率）大概在几万左右。取决于业务操作的复杂性，Lua 脚本复杂性就极高。假如是简单的 key value 查询那性能就会很高。

　　假设上千万、上亿用户同时访问 Redis，QPS 达到 10 万+。这些请求过来，单机 Redis 直接就挂了。系统的瓶颈就出现在 Redis 单机问题上，此时我们可以通过主从复制解决该问题，实现系统的高并发。

redis与lua的关系





## 主从
Redis 的复制（Replication）功能允许用户根据一个 Redis 服务器来创建任意多个该服务器的复制品，其中被复制的服务器为主服务器（Master），而通过复制创建出来的复制品则为从服务器（Slave）。 只要主从服务器之间的网络连接正常，主服务器就会将写入自己的数据同步更新给从服务器，从而保证主从服务器的数据相同。

　　数据的复制是单向的，只能由主节点到从节点，简单理解就是从节点只支持读操作，不允许写操作。主要是读高并发的场景下用主从架构。主从模式需要考虑的问题是：当 Master 节点宕机，需要选举产生一个新的 Master 节点，从而保证服务的高可用性。

优点
Master/Slave 角色方便水平扩展，QPS 增加，增加 Slave 即可；
降低 Master 读压力，转交给 Slave 节点；
主节点宕机，从节点作为主节点的备份可以随时顶上继续提供服务；

缺点
可靠性保证不是很好，主节点故障便无法提供写入服务；
没有解决主节点写的压力；
数据冗余（为了高并发、高可用和高性能，一般是允许有冗余存在的）；
一旦主节点宕机，从节点晋升成主节点，需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预；

主节点的写能力受到单机的限制；

主节点的存储能力受到单机的限制。



## 哨兵

　主从模式中，当主节点宕机之后，从节点是可以作为主节点顶上来继续提供服务，但是需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。
　　于是，在 Redis 2.8 版本开始，引入了哨兵（Sentinel）这个概念，在主从复制的基础上，哨兵实现了自动化故障恢复。如上图所示，哨兵模式由两部分组成，哨兵节点和数据节点：

哨兵节点：哨兵节点是特殊的 Redis 节点，不存储数据；
数据节点：主节点和从节点都是数据节点。

　　Redis Sentinel 是分布式系统中监控 Redis 主从服务器，并提供主服务器下线时自动故障转移功能的模式。其中三个特性为：

监控(Monitoring)：Sentinel 会不断地检查你的主服务器和从服务器是否运作正常；
提醒(Notification)：当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知；
自动故障迁移(Automatic failover)：当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作。

　接下来我们了解一些 Sentinel 中的关键名词，然后系统讲解下哨兵模式的工作原理。

定时任务
　　Sentinel 内部有 3 个定时任务，分别是：

每 1 秒每个 Sentinel 对其他 Sentinel 和 Redis 节点执行 PING 操作（监控），这是一个心跳检测，是失败判定的依据。
每 2 秒每个 Sentinel 通过 Master 节点的 channel 交换信息（Publish/Subscribe）；
每 10 秒每个 Sentinel 会对 Master 和 Slave 执行 INFO 命令，这个任务主要达到两个目的：
	- 发现 Slave 节点；
	- 确认主从关系。

主观下线
　　所谓主观下线（Subjectively Down， 简称 SDOWN）指的是单个 Sentinel 实例对服务器做出的下线判断，即单个 Sentinel 认为某个服务下线（有可能是接收不到订阅，之间的网络不通等等原因）。
　　主观下线就是说如果服务器在给定的毫秒数之内， 没有返回 Sentinel 发送的 PING 命令的回复， 或者返回一个错误， 那么 Sentinel 会将这个服务器标记为主观下线（SDOWN）。

客观下线
　　客观下线（Objectively Down， 简称 ODOWN）指的是多个 Sentinel 实例在对同一个服务器做出 SDOWN 判断，并且通过命令互相交流之后，得出的服务器下线判断，然后开启 failover。
　　只有在足够数量的 Sentinel 都将一个服务器标记为主观下线之后， 服务器才会被标记为客观下线（ODOWN）。只有当 Master 被认定为客观下线时，才会发生故障迁移。

仲裁
　　仲裁指的是配置文件中的 quorum 选项。某个 Sentinel 先将 Master 节点标记为主观下线，然后会将这个判定通过 sentinel is-master-down-by-addr 命令询问其他 Sentinel 节点是否也同样认为该 addr 的 Master 节点要做主观下线。最后当达成这一共识的 Sentinel 个数达到前面说的 quorum 设置的值时，该 Master 节点会被认定为客观下线并进行故障转移。
　　quorum 的值一般设置为 Sentinel 个数的二分之一加 1，例如 3 个 Sentinel 就设置为 2。

哨兵模式工作原理
每个 Sentinel 以每秒一次的频率向它所知的 Master，Slave 以及其他 Sentinel 节点发送一个 PING 命令；
如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过配置文件 own-after-milliseconds 选项所指定的值，则这个实例会被 Sentinel 标记为主观下线； 
如果一个 Master 被标记为主观下线，那么正在监视这个 Master 的所有 Sentinel 要以每秒一次的频率确认 Master 是否真的进入主观下线状态；
当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认 Master 的确进入了主观下线状态，则 Master 会被标记为客观下线；
如果 Master 处于 ODOWN 状态，则投票自动选出新的主节点。将剩余的从节点指向新的主节点继续进行数据复制；
在正常情况下，每个 Sentinel 会以每 10 秒一次的频率向它已知的所有 Master，Slave 发送 INFO 命令；当 Master 被 Sentinel 标记为客观下线时，Sentinel 向已下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次； 
若没有足够数量的 Sentinel 同意 Master 已经下线，Master 的客观下线状态就会被移除。若 Master 重新向 Sentinel 的 PING 命令返回有效回复，Master 的主观下线状态就会被移除。
 优点
哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都有；
主从可以自动切换，系统更健壮，可用性更高；
Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。

 缺点
主从切换需要时间，会丢失数据；
还是没有解决主节点写的压力；
主节点的写能力，存储能力受到单机的限制；


动态扩容困难复杂，对于集群，容量达到上限时在线扩容会变得很复杂。



集群多种架构模式

假设上千万、上亿用户同时访问 Redis，QPS 达到 10 万+。这些请求过来，单机 Redis 直接就挂了。系统的瓶颈就出现在 Redis 单机问题上，此时我们可以通过主从复制解决该问题，实现系统的高并发。
　　主从模式中，当主节点宕机之后，从节点是可以作为主节点顶上来继续提供服务，但是需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。于是，在 Redis 2.8 版本开始，引入了哨兵（Sentinel）这个概念，在主从复制的基础上，哨兵实现了自动化故障恢复。
　　哨兵模式中，单个节点的写能力，存储能力受到单机的限制，动态扩容困难复杂。于是，Redis 3.0 版本正式推出 Redis Cluster 集群模式，有效地解决了 Redis 分布式方面的需求。Redis Cluster 集群模式具有高可用、*可扩展性*、分布式、*容错*等特性。

　Redis Cluster 采用无中心结构，每个节点都可以保存数据和整个集群状态，每个节点都和其他所有节点连接。Cluster 一般由多个节点组成，节点数量至少为 6 个才能保证组成完整高可用的集群，其中三个为主节点，三个为从节点。三个主节点会分配槽，处理客户端的命令请求，而从节点可用在主节点故障后，顶替主节点。
　　如上图所示，该集群中包含 6 个 Redis 节点，3 主 3 从，分别为 M1，M2，M3，S1，S2，S3。除了主从 Redis 节点之间进行数据复制外，所有 Redis 节点之间采用 Gossip 协议进行通信，交换维护节点元数据信息。
　　总结下来就是：读请求分配给 Slave 节点，写请求分配给 Master，数据同步从 Master 到 Slave 节点。

一致性如何保证？？？










## 缓存设计
使用  配置
解决方案
定时读    分布式    定时写
分布式锁  
    setnx实现 添加过期时间解决死锁  
    添加过期时间解决死锁
        引入线程ID对比解决逻辑上锁误删

    锁误删
        lua脚本

    锁续期 
        看门狗机制  
        后台每隔一段时间去延长过期时间

    可重入锁


缓存问题
    缓存穿透（恶意访问）  
    用户请求的id在缓存中不存在
    缓存中也加入空值  或者用布隆过滤器去减少内存空间
    直接通过拦截器拦截
    布隆过滤器
        布隆过滤器（Bloom Filter）是一种空间效率极高的概率型数据结构，用于快速判断一个元素是否存在于集合中。它通过牺牲一定的准确性（存在一定的误判率）来换取极低的内存占用和高效的查询性能。
        布隆过滤器底层使用bit数组存储数据，该数组中的元素默认值是0。
        布隆过滤器第一次初始化的时候，会把数据库中所有已存在的key，经过一些列的hash算法（比如：三次hash算法）计算，每个key都会计算出多个位置，然后把这些位置上的元素值设置成1。
        之后，有用户key请求过来的时候，再用相同的hash算法计算位置。
            如果多个位置中的元素值都是1，则说明该key在数据库中已存在。这时允许继续往后面操作。
            如果有1个以上的位置上的元素值是0，则说明该key在数据库中不存在。这时可以拒绝该请求，而直接返回。

        使用布隆过滤器确实可以解决缓存穿透问题，但同时也带来了两个问题：
            存在误判的情况。
            存在数据更新问题。

        此外，如果想减少误判率，可以适当增加hash函数，图中用的3次hash，可以增加到5次。
        其实，布隆过滤器最致命的问题是：如果数据库中的数据更新了，需要同步更新布隆过滤器。但它跟数据库是两个数据源，就可能存在数据不一致的情况。
        比如：数据库中新增了一个用户，该用户数据需要实时同步到布隆过滤。但由于网络异常，同步失败了。
        这时刚好该用户请求过来了，由于布隆过滤器没有该key的数据，所以直接拒绝了该请求。但这个是正常的用户，也被拦截了。
        很显然，如果出现了这种正常用户被拦截了情况，有些业务是无法容忍的。所以，布隆过滤器要看实际业务场景再决定是否使用，它帮我们解决了缓存穿透问题，但同时了带来了新的问题。
        (1)布隆过滤器的核心原理
            基本结构：
            由一个位数组（Bit Array）和多个哈希函数（Hash Functions）组成。
            位数组初始化时所有位均为 0。
            当插入元素时，通过多个哈希函数计算出多个哈希值，将这些哈希值对应的位数组位置设为 1。
            查询元素时，通过相同的哈希函数计算哈希值，检查对应的位是否全为 1：如果存在 0，则元素一定不在集合中。如果全为 1，则元素可能在集合中（存在误判的可能）。
            示例流程：
            插入元素：假设位数组长度为 10，哈希函数为 h1 和 h2，插入元素 X：
            h1(X) = 3 → 将位数组索引 3 设为 1。
            h2(X) = 7 → 将位数组索引 7 设为 1。
            查询元素：查询元素 Y：
            h1(Y) = 3 → 位数组索引 3 为 1。
            h2(Y) = 5 → 位数组索引 5 为 0。
            → 结论：Y 一定不在集合中。

        (2)布隆过滤器的优缺点
            优点：
            空间效率高：相比哈希表或集合，布隆过滤器占用的内存极小。例如，存储 1 亿个元素，误判率 1% 时仅需约 1.2GB 内存。
            查询速度快：插入和查询时间复杂度为 O(k)（k 为哈希函数数量），与数据规模无关。
            无须存储元素本身：仅保存哈希后的位数组，适合隐私敏感场景。
            缺点：
            存在误判率（False Positive）：可能错误地判断一个不存在的元素为“存在”（无法避免）。误判率与位数组长度、哈希函数数量、元素数量相关。
            无法删除元素：由于位数组是多个元素共享的，直接删除某个元素会破坏其他元素的判断（可通过计数布隆过滤器改进）。
            不支持动态扩容：位数组长度固定，无法动态扩展。

        (3)布隆过滤器的应用场景
            缓存穿透防护：在 Redis 中，将查询过的不存在的 key 存入布隆过滤器。当请求到来时，先通过布隆过滤器判断是否存在，避免查询数据库。
            大数据去重：例如统计独立用户 ID、网页爬虫 URL 去重。
            垃圾邮件过滤：快速判断邮件地址是否在黑名单中。
            分布式系统协调：检查某个资源是否已被其他节点处理。


    缓存空值
        上面使用布隆过滤器，虽说可以过滤掉很多不存在的用户id请求。但它除了增加系统的复杂度之外，会带来两个问题：
        布隆过滤器存在误杀的情况，可能会把少部分正常用户的请求也过滤了。
        如果用户信息有变化，需要实时同步到布隆过滤器，不然会有问题。
        所以，通常情况下，我们很少用布隆过滤器解决缓存穿透问题。其实，还有另外一种更简单的方案，即：缓存空值。
        当某个用户id在缓存中查不到，在数据库中也查不到时，也需要将该用户id缓存起来，只不过值是空的。这样后面的请求，再拿相同的用户id发起请求时，就能从缓存中获取空数据，直接返回了，而无需再去查一次数据库。


    缓存击穿 
    为了保证访问速度，通常情况下，商城系统会把商品信息放到缓存中。但如果某个时刻，该商品到了过期时间失效了。
    此时，如果有大量的用户请求同一个商品，但该商品在缓存中失效了，一下子这些用户请求都直接怼到数据库，可能会造成瞬间数据库压力过大，而直接挂掉。
    设计过期时间   设置永久key
    互斥锁
    逻辑过期
    一个是采用互斥锁（Mutex Lock），在缓存失效时，只允许一个线程去加载数据并更新缓存，其他线程等待。可以通过分布式锁（如 Redis 的 SETNX 命令）实现。
    另一个是采用永不过期策略，对于热点数据，可以不设置过期时间，而是通过后台定时任务主动刷新缓存。

缓存雪崩
    缓存雪崩是缓存击穿的升级版，缓存击穿说的是某一个热门key失效了，而缓存雪崩说的是有多个热门key同时失效。看起来，如果发生缓存雪崩，问题更严重。
    设置随机值
        第一个是为缓存设置随机的过期时间，避免集中失效。例如，在基础过期时间上加上一个随机值。

    高可用集群
        如果使用了redis，可以使用哨兵模式，或者集群模式，避免出现单节点故障导致整个redis服务不可用的情况。
        使用哨兵模式之后，当某个master服务下线时，自动将该master下的某个slave服务升级为master服务，替代已下线的master服务继续处理请求。

    缓存预热
        高频的要求进行定时任务
        我们设置了一个定时任务  隔一段时间读一次放到缓存中

    多级缓存
        第二个采用是多级缓存，使用本地缓存（如 Guava Cache）作为一级缓存，Redis 作为二级缓存，减少对数据库的直接访问。

    降级限流策略
        第三个是采用降级策略，在缓存不可用时，返回默认值或静态页面，避免请求直接打到数据库。


缓存不一致
    缓存失效
        原因：缓存过期或数据更新。
        解决方法：设置合理的过期时间，使用缓存穿透保护（如布隆过滤器）。
        为缓存中的数据设置一个过期时间（TTL, Time-To-Live）。当缓存数据过期后，下次访问时会自动从数据库中更新缓存。这种方式简单易行，但可能导致短时间内的数据不一致。
        主动失效：当数据在数据库中被更新、插入或删除时，主动删除或更新相关的缓存。这样可以确保缓存中的数据始终与数据库中的数据保持一致。

    先删缓存，再更新数据库
        先删除缓存，数据库还没有更新成功，此时如果读取缓存，缓存不存在，去数据库中读取到的是旧值，缓存不一致发生。
        解决方案
        延时双删的方案
        sleep的时间要对业务读写缓存的时间做出评估，sleep时间大于读写缓存的时间即可

    先更新数据库，再删除缓存
        如果反过来操作，先更新数据库，再删除缓存呢？
        这个就更明显的问题了，更新数据库成功，如果删除缓存失败或者还没有来得及删除，那么，其他线程从缓存中读取到的就是旧值，还是会发生不一致。
        消息队列
            这是网上很多文章里都有写过的方案。但是这个方案的缺陷会更明显一点。
            先更新数据库，成功后往消息队列发消息，消费到消息后再删除缓存，借助消息队列的重试机制来实现，达到最终一致性的效果。
            这个解决方案其实问题更多。
            引入消息中间件之后，问题更复杂了，怎么保证消息不丢失更麻烦
            就算更新数据库和删除缓存都没有发生问题，消息的延迟也会带来短暂的不一致性，不过这个延迟相对来说还是可以接受的
            其实，一般大公司本身都会有监听binlog消息的消息队列存在，主要是为了做一些核对的工作。
            这样，我们可以借助监听binlog的消息队列来做删除缓存的操作。这样做的好处是，不用你自己引入，侵入到你的业务代码中，中间件帮你做了解耦，同时，中间件的这个东西本身就保证了高可用。
            当然，这样消息延迟的问题依然存在，但是相比单纯引入消息队列的做法更好一点。
            而且，如果并发不是特别高的话，这种做法的实时性和一致性都还算可以接受的。

        设置缓存过期时间
        每次放入缓存的时候，设置一个过期时间，比如5分钟，以后的操作只修改数据库，不操作缓存，等待缓存超时后从数据库重新读取。
        如果对于一致性要求不是很高的情况，可以采用这种方案。

    原因：数据更新后缓存未同步。
    解决方法：写穿透（Write Through）：更新数据库时同步更新缓存。
    写回（Write Back）：先更新缓存，异步更新数据库。


如何保证Redis与MySQL的数据一致性
    要保证Redis与MySQL的数据一致性，通常有四种解决方案，接下来我将分别进行详细介绍。
    首先是直接操作数据库和Redis，一共有六种常见的方式，它们实现简单，但可能在高并发场景中面临一致性问题，且影响系统性能。前三种相对不好，后三种相对较好。
    第一种是先写MySQL，再写Redis，这种方式存在较大风险，尤其是Redis更新失败时，缓存与数据库数据不一致。
    第二种是先写Redis，再写MySQL，这种方案虽然提高了性能，但存在数据丢失的风险，尤其是在Redis出现故障或丢失数据时，可能导致数据不一致。
    第三种是先删除Redis，再写MySQL，虽然一定程度上避免了缓存数据不一致的问题，但会影响性能，因为每次更新都需要重建缓存，同时也无法保证缓存更新及时性，尤其是在高并发情况下。
    第四种是先删除Redis，再写MySQL，再删除Redis，这种方案会影响性能，尤其是在高负载环境中频繁操作缓存和数据库时。
    第五种是先写MySQL，再删除Redis，虽然保证了数据库一致性，但可能会出现缓存未及时更新的情况，导致短时间内缓存数据过期，影响系统的响应速度。
    第六种是通过Binlog异步更新Redis，这种方案保证了高一致性，并且由于是异步的，可以较少地影响性能，适合对一致性要求较高的场景。
    然后是使用Redis + Kafka实现缓存与数据库的一致性，在写入数据时，可以将操作信息发送到Kafka等消息队列，然后由消费者（可以是一个专门的服务）来处理数据库和缓存的同步。这种方案通过消息队列解耦了数据库和缓存的操作，确保两者的一致性。Kafka的可靠性保证了消息不丢失，因此可以保障一致性，但需要额外的基础设施来管理消息队列。
    其次是使用Redis + TCC事务管理，TCC（Try-Confirm-Cancel）事务模型适用于分布式事务管理。在写入Redis和MySQL时，可以先在Redis进行预写操作（Try），然后确认MySQL的数据更新（Confirm），如果遇到失败，可以取消Redis的操作（Cancel）。这种方式通过分布式事务的处理，能够确保两者一致性，但需要额外的事务管理中间件，增加系统复杂度。
    最后是使用分布式数据库中间件（如Sentinel, Canal等），Redis的高可用架构可以借助Sentinel实现主从复制，保证缓存的高可用性和一致性。与此同时，Canal可以作为MySQL的增量数据订阅工具，实时同步数据库变更到Redis缓存。通过这种方式，可以实现高效的数据一致性保障，但配置和维护较为复杂。

1.如何选择合适的方案来保证 Redis 与 MySQL 的数据一致性？
    (1)直接操作数据库和 Redis（六种方案）
    适用场景 ：
    低频写入、高读取 的场景（如配置信息缓存）。
    对一致性要求不高的场景（允许短时间不一致）。
    选择建议 ：
    优先选择第六种（Binlog 异步更新 Redis） ：通过数据库的 Binlog 异步同步到 Redis，既能保证最终一致性，又不会显著影响性能。
    避免前三种方案 ：如“先写 MySQL 再写 Redis”可能导致缓存更新失败，而“先写 Redis 再写 MySQL”存在数据丢失风险。
    (2)使用 Kafka 等消息队列
    适用场景 ：
    高并发、高可靠性的分布式系统（如电商订单、支付系统）。
    需要解耦数据库与缓存操作的场景。
    选择建议 ：
    确保消息队列的可靠性（如 Kafka 的持久化、副本机制）。
    需要处理消息重复消费问题（通过幂等性设计）。
    (3)TCC 事务管理
    适用场景 ：
    对一致性要求极高的场景（如金融交易）。
    需要严格保证 Redis 和 MySQL 操作原子性的场景。
    选择建议 ：
    需引入分布式事务中间件（如 Seata），会增加系统复杂度。
    适用于核心业务，但需权衡开发成本和性能开销。
    (4)分布式中间件（如 Canal）
    适用场景 ：
    需要实时同步数据库变更到 Redis 的场景（如实时数据大屏）。
    已有 MySQL 主从架构，希望复用 Binlog 的场景。
    选择建议 ：
    需要维护 Canal 服务和 Redis 同步逻辑，适合技术栈成熟的团队。
    结合 Redis 的过期策略，避免缓存雪崩。




## 持久化策略
Redis 是一种高性能的键值存储系统，它支持多种数据结构，并且广泛用于缓存、消息队列等场景。为了实现数据不丢失，Redis 提供了多种持久化机制，主要包括 RDB（Redis Database）、 AOF（Append-Only File）和混合持久化
RDB快照
    将某一时刻的内存数据，以二进制的方式写入磁盘；
    RDB 快照可以通过手动命令（如 SAVE 或 BGSAVE）或配置文件中的时间策略（如每隔一定时间或一定写操作次数后自动触发）来生成。
    它的执行过程主要分为三步，
        第一步是当触发 RDB 持久化时，Redis 会 fork 出一个子进程；
        第二步是子进程负责将当前内存中的数据完整地写入到一个临时文件中；
        第三步是在写入完成后，子进程用这个临时文件替换掉旧的 RDB 文件，完成持久化。

    RDB 文件是紧凑的二进制格式，适合备份和恢复，尤其是在恢复大数据集时性能较好，但是数据可能会有一定的丢失风险，因为它是基于时间点的快照，两次快照之间的数据可能无法保存。

AOF日志  AOF 是 Redis 的另一种持久化方式，它通过记录每个写操作命令来保证数据的完整性。
    每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；
    它的工作流程主要分为三步，
    第一步是记录写操作，每当 Redis 执行一个写操作时，该操作会被追加到 AOF 文件的末尾；  
        在执行写命令时，Redis会将命令首先追加到AOF缓冲区（aof_buf）。这个缓冲区暂时存储命令，以减少磁盘I/O的频率。通过事件循环机制，写命令会被转换为Redis协议格式，并追加到缓冲区中，确保命令执行效率不受影响。

    第二步是文件重写，随着写操作的增加，AOF 文件可能会变得很大，Redis 提供了 AOF 重写机制，通过创建一个新的 AOF 文件来压缩历史记录，只保留最终状态；
        AOF缓冲区中的命令并不会立即写入磁盘，而是根据配置的同步策略来决定写入时机。Redis提供三种同步策略：
        always：每次写命令后立即写入并同步到AOF文件。虽然数据安全性高，但性能大幅下降，不推荐使用。
        everysec：每秒将AOF缓冲区中的命令写入并同步到文件，兼顾了性能与数据安全性，是默认推荐的策略。
        no：不进行主动同步，操作系统决定写入时机，可能导致数据丢失，适用于对数据安全性要求不高的场景。
        文件写入和同步的区别在于，写入操作仅将数据写入操作系统的缓冲区，而同步操作会确保数据实际写入磁盘。Linux系统中，写入操作通过write调用，同步通过fsync或fdatasync完成。
        随着Redis运行时间的增加，AOF文件会逐渐增大，可能导致占用大量磁盘空间并影响重启加载速度。为了解决这一问题，Redis引入了AOF重写机制。AOF重写会根据当前数据集生成一个新的AOF文件，仅保留恢复当前数据所需的最小命令集合，显著减少文件大小。该过程是通过fork一个子进程来进行，子进程根据内存中的数据生成新的AOF文件，而主进程继续处理客户端请求。当重写完成后，主进程将会用新文件替换旧文件。通过配置auto-aof-rewrite-percentage和auto-aof-rewrite-min-size，可以自动触发AOF重写，或者使用BGREWRITEAOF命令手动触发。

    第三步是恢复数据，当 Redis 启动时，会读取 AOF 文件并重新执行其中的命令，从而恢复数据。
        在Redis重启时，如果启用了AOF持久化功能，系统会通过加载AOF文件来恢复数据库状态。Redis通过创建伪客户端读取AOF文件并执行每个写命令来恢复数据。如果AOF文件损坏，Redis会停止启动并显示错误信息，此时可以使用redis-check-aof工具进行修复。

    AOF 的数据安全性更高，可以配置为每次写操作都同步到磁盘，几乎不会丢失数据，而且它是可读的文本文件，便于调试和分析，但是它的文件体积通常比 RDB 大，恢复速度较慢，且频繁的磁盘写入可能会影响性能。

混合持久化方式
    Redis 4.0 新增的方式，集成了 AOF 和 RDB 的优点；
    最后是混合持久化，在 Redis 4.0 及之后版本中，引入了混合持久化的方式，这种方式首先以 RDB 格式保存当前数据的快照，然后再追加后续的写操作命令，这种方式既能快速加载数据，又能减少文件体积，同时保持较高的数据安全性。

过期删除策略
    Redis 是一种高性能的键值存储系统，它支持为每个键设置过期时间（TTL，Time To Live）。为了高效地管理这些带有过期时间的键，Redis 采用了三种主要的过期删除策略：惰性删除、定时删除和定期删除。接下来我会详细讲述这三种策略的触发时机、执行过程和优缺点。
    第一个是惰性删除（Lazy Deletion）
        当客户端尝试访问某个键时会被触发，它的执行过程主要分为三步，
        首先，Redis 会检查该键是否设置了过期时间。
        其次，如果当前时间已经超过该键的过期时间，则 Redis 会立即删除该键，并返回空值给客户端。
        最后，如果键未过期，则正常返回键对应的值。
        惰性删除的优点是不会额外占用 CPU 资源，只有在访问键时才会触发删除操作。当时，它的缺点是，当某些过期键如果长时间未被访问时，仍然会一直占用内存，进而导致内存浪费。

    第二个是定时删除（Immediate Deletion）
        当键的过期时间到达时会被触发，Redis 立即删除该键。它的执行过程只有两步，
        首先，让 Redis 使用一个内部定时器来监控键的过期时间。
        然后，当某个键的过期时间到达时，Redis 会立即将其从内存中删除。
        定时删除的优点是能保证过期键在过期瞬间被清理，避免内存浪费。当时，它的缺点是，采用此策略对 CPU 的消耗较大，尤其是在大量键同时过期时，可能会影响 Redis 的性能。

    第三个是定期删除（Periodic Deletion）
        让 Redis 在后台定期运行一个任务来清理过期键。它执行过程主要分为三步，
        首先，Redis 会从设置了过期时间的键集合中随机抽取一部分键。
        其次，检查这些键是否已经过期，如果过期则删除。
        最后，根据配置的频率和限制条件，控制每次删除的数量，避免对性能造成过大影响。
        定期删除的优点是能在一定程度上主动清理过期键，减少内存浪费。且通过随机抽样和限制删除数量，平衡了性能和内存使用。但是，它的缺点是，删除操作很随机，无法保证所有过期键都能被及时清理。


内存淘汰策略
    Redis 过期删除策略和内存淘汰策略是两种不同的机制，分别用于处理 Redis 数据的过期和内存管理问题。它们的区别如下：
    (1)过期删除策略（Expiration Policy）
        过期删除策略是 Redis 用来自动删除已设置过期时间（TTL）的键的机制。当某个键的生存时间（TTL）到期时，Redis 会根据配置的过期删除策略自动删除该键。它主要是解决数据本身过期的问题。
        主要特点：
        触发条件：当某个键的过期时间到期，Redis 会删除这个键。
        过期时间设置：可以通过 EXPIRE 或 SET 命令设置键的过期时间。

    (2)内存淘汰策略（Eviction Policy）
        内存淘汰策略是 Redis 在内存达到最大限制时，用来决定如何处理多余数据的机制。当 Redis 的内存使用达到设置的上限（maxmemory 配置项），Redis 会选择根据配置的淘汰策略删除一些键，以腾出空间。
        主要特点：
        触发条件：当 Redis 占用的内存超过配置的最大内存限制时，触发内存淘汰策略。
        内存限制设置：可以通过 maxmemory 配置项设置 Redis 的最大内存。

    常见的内存淘汰策略：
        volatile-random：随机淘汰设置了过期时间的任意键。适用于没有其他明确需求时，随机删除一些数据以腾出内存。
        volatile-ttl：优先淘汰那些即将过期的键。对于设置了过期时间的键，系统会倾向于删除最早过期的键，确保数据不会被长时间保留。
        volatile-lru：淘汰所有设置了过期时间的键中，最久未使用的键。LRU（Least Recently Used）算法会选择最近最少访问的数据进行淘汰。Redis 3.0 之前默认使用此策略。
        volatile-lfu：淘汰所有设置了过期时间的键中，最少使用的键。LFU（Least Frequently Used）算法会选择访问频率最低的键进行淘汰。此策略是在 Redis 4.0 后新增的。
        allkeys-random：从所有键中随机淘汰任意一个键。这种方式不考虑键是否设置了过期时间，适用于不关心哪些键被淘汰的场景。
        allkeys-lru：淘汰所有键中最久未使用的键。LRU 算法会选择那些最久没有访问过的数据进行淘汰，适用于内存压力较大的场景。
        allkeys-lfu：淘汰所有键中最少使用的键。LFU 算法会选择访问频率最低的键进行淘汰，这也是 Redis 4.0 后新增的一种策略，能够更细粒度地管理内存。
        noeviction：当 Redis 达到最大内存限制时，不进行任何淘汰操作，而是直接返回错误。这种策略适用于对内存限制非常严格的场景，确保不会丢失任何数据。


## 高可用
在 Redis 集群中，每个节点（机子）存储的内容不是完全一样的。Redis 集群采用分片（sharding）机制，将数据分散存储在多个节点上，以实现水平扩展、容错和高可用性。因此，每个节点只存储一部分数据，而不是所有节点存储相同的全部数据。
主从复制
    哨兵模式
    在 Redis 集群中，每个节点（机子）存储的内容不是完全一样的。Redis 集群采用分片（sharding）机制，将数据分散存储在多个节点上，以实现水平扩展、容错和高可用性。
    因此，每个节点只存储一部分数据，而不是所有节点存储相同的全部数据。
    切片集群

怎么判断 Redis 某个节点是否正常工作？(363/1759=20.6%)
    判断 Redis 某个节点是否正常工作是一个常见的运维和开发需求。接下来我会详细讲述判断 Redis 节点正常工作五种常见方式。
    第一种是采用 PING 命令，它是 Redis 内置命令，用于测试 Redis 服务是否可用。如果 Redis 节点正常工作，执行 PING 命令会返回 PONG。如果未收到 PONG 或连接超时，则说明节点可能存在问题。
    第二种是采用 INFO 命令，它也是 Redis 内置命令，INFO 命令可以返回 Redis 节点的详细运行信息，包括内存使用、连接数、持久化状态等。通过解析这些信息，可以判断节点是否处于正常状态。例如，检查 role 字段可以确认节点是主节点还是从节点，检查 connected_clients 可以确认是否有过多的客户端连接。
    第三种是采用 CLUSTER INFO 命令（集群模式），它还是 Redis 内置命令，如果 Redis 运行在集群模式下，可以使用 CLUSTER INFO 命令查看集群的状态。重点关注 cluster_state 字段，如果值为 ok，则表示集群正常；如果是 fail，则说明集群中有节点不可用。
    第四种是采用 Telnet 或 Netcat，它们属于外部工具，用于测试 Redis 节点的端口是否可达。例如，尝试连接到 Redis 的默认端口 6379，如果连接失败，说明节点可能宕机或网络有问题。
    第五种是采用监控系统，配置 Prometheus、Grafana 等监控工具，实时监控 Redis 的性能指标（如内存使用率、QPS、延迟等）。如果某些指标超出阈值或出现异常波动，可能是节点出现问题。

异常情况及可能原因
    如果执行 PING 命令后未收到 PONG 或连接失败，可能的原因包括：
    网络问题：客户端与 Redis 节点之间的网络连接中断或延迟过高，导致命令无法到达 Redis 或响应超时。
    Redis 服务未启动：Redis 节点可能由于某种原因（如配置错误、资源不足）未能正常启动。
    防火墙限制：防火墙规则可能阻止了客户端访问 Redis 的端口（默认为 6379）。
    Redis 内部故障：Redis 节点可能由于内存溢出（OOM）、崩溃或其他内部错误而无法处理请求。
    认证问题：如果 Redis 配置了密码保护（通过 requirepass 参数），未提供正确的密码可能导致命令被拒绝。

解决方法
    检查网络连通性：使用 ping 或 telnet 测试客户端与 Redis 节点之间的网络连接。
    确认 Redis 服务状态：通过系统命令（如 ps aux | grep redis 或 systemctl status redis）检查 Redis 是否正在运行。
    检查日志文件：查看 Redis 日志（通常位于 /var/log/redis/redis.log）以定位具体问题。
    确保防火墙规则允许访问 Redis 端口。
    如果启用了密码保护，确保在客户端中正确提供密码（例如，使用 AUTH <password> 命令）。

## 高性能
速度
    单线程
        避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。
        Redis 单线程指的是「接收客户端请求->解析请求 ->进行数据读写等操作->发生数据给客户端」这个过程是由一个线程（主线程）来完成的，这也是我们常说 Redis 是单线程的原因。
        但是，Redis 程序并不是单线程的，Redis 在启动的时候，是会**启动后台线程（BIO）**的：
        Redis 在 2.6 版本，会启动 2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务；
        Redis 在 4.0 版本之后，新增了一个新的后台线程，用来异步释放 Redis 内存，也就是 lazyfree 线程。例如执行 unlink key / flushdb async / flushall async 等命令，会把这些删除操作交给后台线程来执行，好处是不会导致 Redis 主线程卡顿。因此，当我们要删除一个大 key 的时候，不要使用 del 命令删除，因为 del 是在主线程处理的，这样会导致 Redis 主线程卡顿，因此我们应该使用 unlink 命令来异步删除大key。
        之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。
        后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。

    多路I/O复用
        采用了 I/O 多路复用机制处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。


## 实际应用
优惠券
    Redis 计数器  Lua 脚本Redis
    全局ID生成器
        避免id 的规律性  
        受单表数据量的限制


达人探店
    基于List 的点赞列表
    基于SortedSet 的点赞排行榜

附近的商户
    Redis 的GeoHash的应用

UV统计
    Redis 的HyperLogLog的统计功能

用户签到
    Redis 的BitMap 数据统计功能


## 一致性


