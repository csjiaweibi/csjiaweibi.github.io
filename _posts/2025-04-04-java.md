---
title: 'Java'
date: 2025-04-04
permalink: /posts/2025/04/blog-post-1/
tags:
  - JAVA SE
---

打好基础

常见八股要注重底层实现

## 待做的事
再多读源码看看 

## 学习建议
- **多敲代码**：实践是掌握编程的最佳方式，通过运行代码直观地加深记忆。
- **多读源码**：阅读Java源码是难点，未来我会分享更多读源码的经验。
- **关注最新版本**：Java 24（2025年3月18日发布）引入了新特性，如虚拟线程和KDF API，建议了解这些更新。

本文参考《Java核心技术》、《深入理解Java虚拟机》、《Java并发编程之美》。
33.
## Java 重点内容

Java语言以简单、强大的库、健壮的检查机制、跨平台性和可移植性著称。
它是半编译语言（字节码+运行时解释或JIT编译），具有动态性。

深入学习Java需要：
- 阅读源码
- 深入理解JVM和JUC（Java Util Concurrency）
- 注解+反射+设计模式共同构成了Java框架。

### 基础知识
- 基本数据类型 + 包装类型 + 大数 + 异常 + 泛型 + 注解 + 反射 + Lambda表达式 + 字节流 + 序列化 + I/O + 动态代理（方法拦截与增强） + Stream

### 面向对象
- 单继承 + 接口 + 多态 + 封装 + 修饰符 + 抽象类 + 内部类

### 重点类
- Object类 + Class类 + String类

### 容器
- ArrayList类 + LinkedList类 + HashMap类 + PriorityQueue类

### JVM
- 类加载子系统
- 运行时数据区（堆、运行时常量池、本地方法栈、程序计数器、Java虚拟机栈、方法区）
- 垃圾收集器（GC）
- 执行引擎（包括解释器和JIT编译器）
- 本地方法接口（JNI）和本地方法库

### JRE和JDK
- JRE = JVM + 强大的库
- JDK = JRE + 编译器 + 调试器 + 开发工具

### JUC（Java Util Concurrency）
- 多线程 + 线程池 + AQS + ConcurrentHashMap + AbstractQueuedSynchronizer + ConditionObject + CopyOnWriteArrayList + 阻塞队列 + 内存泄露 + 死锁 + 线程安全 + ThreadLocal + CAS + ReentrantLock + Atomic + 线程安全的集合
- 新增：Java 24引入轻量级锁机制（JEP 444），默认使用LM_LIGHTWEIGHT模式，改善并发性能。

### 锁
- 死锁 + 锁的升级 + 锁的状态

### 实用工具
- IDEA + jconsole + VisualVM（用于性能分析）

## 知识点
- **序列化**：
- **常见集合**：HashMap的插入、扩容
  - 计算哈希值，均匀散列，计算桶位置，插入链表或者红黑树，扩容检查
  - ConcurrentHashMap 如何实现并发
    - 1.7
      - 由于使用了分段锁，多个线程可以同时操作不同段的数据，而不需要锁定整个哈希表。这大大提高了并发性能，但同一段内的操作仍然是互斥的。
      - ConcurrentHashMap 在 JDK 1.7 中使用了**分段锁（Segment）**的结构。整个哈希表被分割成多个段（Segment），每个段是一个独立的锁（ReentrantLock），相当于将整个哈希表分成多个小的哈希表。默认情况下，分为 16 个段。
      - 这种方式虽然线程安全，但性能开销较大，尤其是在高并发场景下。
      - 并发性：由于使用了分段锁，多个线程可以同时操作不同段的数据，而不需要锁定整个哈希表。这大大提高了并发性能，但同一段内的操作仍然是互斥的。
      size 的计算：在 JDK 1.7 中，size() 方法并不是直接返回当前元素的数量，而是需要遍历所有 Segment，统计每个 Segment 中的元素个数。为了保证线程安全，size() 方法会尝试多次（默认 2 次）快速统计，如果两次统计结果一致，则认为当前大小是准确的；如果不一致，则会对整个 ConcurrentHashMap 加锁（使用全局锁），确保在锁保护下准确计算大小。这种方式虽然线程安全，但性能开销较大，尤其是在高并发场景下。
    - 1.8
      - 放弃了 Segment 的分段锁设计，改用了与 HashMap 类似的数组 + 链表 + 红黑树结构（当链表过长时转换为红黑树）。并发控制不再依赖于 Segment，而是使用CAS（Compare-And-Swap）操作和synchronized 关键字来保证线程安全
      - synchronized + CAS + 红黑树
      - JDK 1.8 中，size() 方法的实现发生了重大变化，不再像 JDK 1.7 那样需要多次尝试或加全局锁。相反，ConcurrentHashMap 维护了一个 volatile 的 sizeCtl 变量和 CounterCell 数组来统计元素数量，这些机制确保了高并发下的线程安全。
      - 并发性：每个桶（bucket）上的操作（比如 put、get、remove）都使用 synchronized 锁保护特定桶，而不是整个哈希表或段。这进一步提高了并发性能，因为不同桶的操作可以并行执行，而不需要相互干扰。
      - size 的计算：JDK 1.8 中，size() 方法的实现发生了重大变化，不再像 JDK 1.7 那样需要多次尝试或加全局锁。相反，ConcurrentHashMap 维护了一个 volatile 的 sizeCtl 变量和 CounterCell 数组来统计元素数量，这些机制确保了高并发下的线程安全。
      - DK 1.8 中 size 方法如何保证线程安全
在 JDK 1.8 中，ConcurrentHashMap 的 size() 方法（或更准确地说，是通过 mappingCount() 方法来获取元素数量）使用了以下机制来保证线程安全：

关键数据结构
sizeCtl：一个 volatile 变量，用于控制表的大小、初始化和扩容。它不仅仅是大小的计数器，还用于协调并发操作。
CounterCell：一个数组，用于在高并发场景下分散统计计数。每个 CounterCell 是一个独立的计数单元，线程可以更新自己的 CounterCell，从而减少竞争。
size 计算过程
ConcurrentHashMap 没有直接维护一个全局的、精确的元素计数，因为在并发环境中，元素的增删是动态的，直接计数会带来很大的锁竞争开销。相反，JDK 1.8 采用了以下策略：

基于 CounterCell 的分散计数：
当多个线程同时修改 ConcurrentHashMap（比如 put 或 remove 操作）时，它们不会直接修改同一个计数器，而是通过 CounterCell 数组分散计数。
每个线程尝试更新自己的 CounterCell，使用 CAS 操作保证线程安全。如果 CAS 失败（说明其他线程也在修改），线程会回退到使用锁或重新尝试。
sizeCtl 的作用：
sizeCtl 是一个 volatile 变量，用于近似跟踪当前元素数量。它并不是精确的计数，而是通过 CounterCell 数组的和来估算。
在低并发场景下，sizeCtl 可能直接反映当前的大小；在高并发场景下，sizeCtl 的值可能滞后，但这通常是可以接受的，因为 size() 方法的调用通常不要求绝对精确。
mappingCount() 方法：
JDK 1.8 中，size() 方法实际上是 mappingCount() 的别名，用于返回当前映射的元素数量。
mappingCount() 方法会遍历所有 CounterCell，将它们的计数相加，并加上 sizeCtl 的修正值（如果有）。由于 CounterCell 和 sizeCtl 都是 volatile 变量，读取这些值是线程安全的，无需额外的同步。
最终一致性：
mappingCount() 返回的值可能不是 100% 精确的实时值，因为在并发修改期间，某些操作可能尚未反映到总计中。但这通常不会影响程序的正确性，因为 ConcurrentHashMap 的设计目标是提供高并发性能，而不是绝对精确的实时统计。
    - 为什么重写equals方法时，必须重写hashCode方法？
      - 当把对象添加到HashSet时，HashSet会先计算对象的hashCode值来判断对象加入的位置，同时也会与其他已经加入的对象的hashCode值做比较，如果没有相同的hashCode，则认为没有重复的对象。如果有相同的hashCode（发生碰撞），则会调用equals()方法来判断对象是否相同。如果相同，则不会让其加入成功。如果不同，则重新散列到其他位置。这样就减少使用equals的次数，提高了执行速度。
      - Java 的 Object 类中定义了 equals 和 hashCode 方法之间的契约，主要包括以下几点：
        - 相等性一致性：如果两个对象通过 equals 方法判断为相等（即 a.equals(b) 返回 true），那么它们的 hashCode 值必须相同（即 a.hashCode() 必须等于 b.hashCode()）。
        - 非相等性一致性：如果两个对象通过 equals 方法判断为不等（即 a.equals(b) 返回 false），它们的 hashCode 值不一定必须不同，但最好不同（虽然允许相同，但这样会降低哈希表的效率）。
        这个契约的目的是确保基于哈希的集合（比如 HashMap 和 HashSet）能够正常工作。如果违反这个契约，可能会导致不可预期的行为，比如对象无法正确存储或检索。
- **对象的创建方式**：new关键字、反射、克隆、序列化等。
- **对象的创建过程**：类加载、分配内存（根据堆内存规整情况选择指针碰撞和空闲列表）、初始化、对象头设置
  - 解决多线程内存抢占情况（CAS+TLAB（本地线程缓冲区））
- **反射的原理**：通过Class对象操作类、方法、字段，动态调用。所有对象都会维护一个运行时类型标识
  - 第一个是框架开发，很多Java框架都有使用反射，比如如Spring、Hibernate等。
  - 第二个是动态代理，动态代理是反射的一个重要应用，常用于AOP（面向切面编程）。通过反射，我们可以在运行时动态生成代理类，拦截方法调用并添加额外逻辑。
  - 第三个是注解处理，注解本身不会对程序产生任何影响，但通过反射，我们可以在运行时读取注解信息并执行相应的逻辑。
  - 第四个是插件化开发，在某些场景下，我们需要动态加载外部的类或模块。反射可以帮助我们在运行时加载这些类并调用其方法，从而实现插件化开发。
  - 第五个是测试工具，单元测试框架（如JUnit）利用反射来发现和运行测试方法，而无需手动指定每个测试用例。
- **动态代理的使用场景**：AOP、RPC框架，如Spring中的事务管理。
  - 代理模式
    我们使用代理对象来代替对真实对象(realobject)的访问，这样就可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。代理模式的主要作用是扩展目标对象的功能，比如说在目标对象的某个方法执行前后你可以增加一些自定义的操作。
  - 从JVM角度来说，动态代理是在运行时动态生成类字节码，并加载到JVM中的。说到动态代理，SpringAOP、RPC框架应该是两个不得不提的，它们的实现都依赖了动态代理。
- **类加载过程**：
  - 加载、链接（验证、准备、解析）、初始化。
- **类加载器类型**：
  - 启动类加载器（加载核心库）
  - 扩展类加载器（加载扩展库）
  - 应用程序类加载器（加载用户自定义库）
  - 自定义类加载器（开发者自定义逻辑）
    - tomcat自定义类加载器
      - 破坏了双亲委派模型
      - 
- **锁机制**：
  - 偏向锁：一种优化锁机制，假设只有一个线程访问对象，减少同步开销。
    - 当启用偏向锁时，锁标志记录偏向的线程 ID，减少锁竞争。
    - 在偏向锁或轻量级锁中，记录锁的拥有者，辅助多线程同步。
- **运行时数据区**：
  - 程序计数器：记录当前线程执行的字节码指令。
  - Java虚拟机栈：存储局部变量、操作数栈、方法调用和返回。
  - 本地方法栈：执行native方法（C/C++编写）。
  - 堆：存储对象实例和数组，分为年轻代（Eden区和Survivor区）和老年代，含字符串常量池。
  - 方法区：存储类信息、常量池、静态变量、即时编译代码（HotSpot中由元空间实现）。
  - 运行时常量池：方法区的一部分，存储字面量和符号引用。
- **对象的内存布局**：
  - 对象头（MarkWord和元数据指针）、实例数据、对齐填充。
  - MarkWord记录哈希码、GC分代年龄、锁状态等。
- **对象回收**：
  - 判断存活： 所谓的根就是 在main方法里面new出来的对象都是根对象
    - 虚拟机栈(栈帧中的局部变量表)中引用的对象
    - 本地方法栈(Native方法)中引用的对象方法区中类静态属性引用的对象方法区中常量引用的对象
    - 所有被同步锁持有的对象JNI（JavaNativeInterface）引用的对
- **垃圾回收**：
  - 垃圾回收区域
    - Eden区、老年代、
  - 算法：标记-清除、复制、标记-整理（老年代）、分代收集。
  - 引用类型：强引用、弱引用、软引用、虚引用。
  - 垃圾收集器：CMS、G1、Serial、ParNew，Java 24新增实验性Generational Shenandoah GC。
    - CMS垃圾回收过程  current mark sweep收集器
      - 初试标记  单线程运行  stop the world 根据gc roots标记能直达的对象
      - 并发标记（三色标记）  无停顿  和用户线程同时运行  从gc roots直达对象开始遍历整个对象图
      - 重新标记 多线程运行 需要stop the world 标记并发标记阶段产生的对象
      - 并发清楚 无停顿 和用户线程同时运行 清理掉标记阶段标记的死亡的对象
      - CMS 的优点是以响应时间优先，停顿时间短
        - 缺点是 标记清除算法内存碎片比较多
        - 并发性能依赖CPU处理器 抢占用户线程资源
        - 并发清除阶段 用户线程产生的浮动内存 必要到下一次垃圾回收才能处理
    - G1垃圾回收过程  Garbage-First
      - 将Java堆划分为多个大小相等的独立区域，每个区域可以根据需要，扮演Eden空间，Survivor空间，老年代空间
      - 提供更精细的控制、可预测的停顿时间、内存碎片的控制、优先级处理  （指针碰撞
      - 初试标记 STW 
      - 并发标记 可达性分析 
      - 最终标记 = 重新标记  标记的范围更小
      - 筛选回收 制定回收计划  选择多个region 构成回收集 把回收集中Region的存活对象复制到空的Region中，再清理掉整个旧的Region
      - 大内存环境下引入G1 发挥性能更好
    - 开发中如何选择
- JVM 待更新  35问第15问

- **如何创建一个线程**：
  - 继承Thread类、实现Runnable接口、使用ExecutorService
  - 生命周期
    - 创建 就绪 运行 等待（waiting） 阻塞（锁）  终止
  - **如何实现上下文切换的**
    - sleep(),wait() 时间片用完 调用了阻塞类型的系统中断 被终止
    - 将当前线程的寄存器状态、程序计数器、栈信息等保存到内存中。
    - 根据线程调度算法，如：时间片轮转、优先级调度等，选择下一个要运行的线程。
    - 加载下一个线程的上下文，从内存中恢复所选线程的寄存器状态、程序计数器和栈信息。
    - CPU开始执行被加载的线程的代码。
  - **减少交换方法**
    - 使用无锁数据结构 通过CAS等无锁操作减少线程间的锁竞争
    - 协程或者异步编程 使用轻量级的协程或异步模型（如Java的CompletableFuture或Kotlin的协程）替代传统的线程模型，减少上下文切换的频率。
    - 优化线程调度策略：根据任务的特点选择合适的线程调度算法，例如优先处理高优先级任务。
  - 
- **CAS算法**
  - CAS的全称是CompareAndSwap（比较与交换），用于实现乐观锁，被广泛应用于各大框架中。CAS的思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。
    - ABA问题
  - CAS 通常用于实现高并发的无锁算法（如原子类、并发容器），避免了传统锁的开销（如上下文切换）。
  - 原子性：CAS 操作是原子的，由硬件保证不会被中断。
  - sun.misc.Unsafe 类和 java.util.concurrent.atomic
  - Atomic 类：如 AtomicInteger、AtomicLong、AtomicReference 等，用于实现计数器、标志位等。
  - 并发容器：如 ConcurrentHashMap 使用 CAS 实现无锁的哈希表操作。
  - AQS（AbstractQueuedSynchronizer）：Java 锁（如 ReentrantLock）和同步器（如 Semaphore）的底层依赖 CAS。
  - CAS 操作只能针对单个变量进行原子操作。如果需要对多个变量进行原子操作，CAS 本身无法直接支持。
- **JMM**
  - MM(Java内存模型)主要定义了对于一个共享变量，当另一个线程对这个共享变量执行写操作后，这个线程对这个共享变量的可见性。

- **锁**
  - 死锁
    - 产生死锁的四个必要条件：
    - 互斥条件：该资源任意一个时刻只由一个线程占用。
    - 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
    - 不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
    - 循环等待条件:若干线程之间形成一种头尾相接的循环等待资源关系。
  - 锁的状态    锁升级的目标是根据竞争程度选择最合适的同步策略，减少性能开销。
    -   偏向锁（Biased Locking）：偏向锁是一种优化机制，用于减少无竞争情况下的同步开销。当一个线程第一次获取锁时，JVM会将锁标记为偏向该线程，并记录线程ID。如果后续该线程再次尝试获取锁，无需进行额外的同步操作，直接判断线程ID是否匹配即可。偏向锁适用于只有一个线程访问同步块的场景。
    -   轻量级锁（Lightweight Locking）：当有第二个线程尝试获取已经被偏向的锁时，偏向锁会升级为轻量级锁。轻量级锁通过CAS（Compare-And-Swap）操作来尝试获取锁。如果CAS操作成功，则线程获取锁；如果失败，则进入自旋等待状态，尝试多次获取锁。
        -   轻量级锁是当偏向锁失效或锁开始出现轻微竞争时的一种优化机制。它的目标是减少传统重量级锁（操作系统级互斥锁）带来的性能开销，如线程挂起和恢复等。
        -   是一种轻量级同步机制，线程在获取锁失败时不断检查锁是否可用，避免立即阻塞。
    -   重量级锁（Heavyweight Locking）：当多个线程竞争锁且自旋等待无法快速获取锁时，轻量级锁会升级为重量级锁。重量级锁会将未获取锁的线程挂起（进入阻塞状态），并由操作系统调度。这种方式会带来较大的性能开销，因为线程的挂起和唤醒需要上下文切换。
    -   无锁（No Lock） → 偏向锁（Biased Locking） → 轻量级锁（Lightweight Locking） → 重量级锁（Heavyweight Locking）。
- **ThreadLocal**
  - 线程本地存储机制
  - 就是为了操控ThreadLocalMap
  - 主要原因是ThreadLocalMap中的Entry是弱引用,而Value是强引用,如果不主动调用remove()方法清理,即使线程结束,这些对象也可能无法被垃圾回收。
  - 
- **类库**
  - ThreadLocal
  - Unsafe
  - Atomic
  - AQS
      AQS就是一个抽象类，主要用来构建锁和同步器。
      AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。
      CLH(Craig,Landin,andHagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。在CLH同步队列中，一个节点表示一个线程，它保存着线程的引用（thread）、当前节点在队列中的状态（waitStatus）、前驱节点（prev）、后继节点（next）。
    - 公平锁和非公平锁的底层实现
      - 公平锁会检查AQS队列中是否存在线程排队，如果有线程在排队，则当前线程也进行排队
      - 如果是非公平锁，则不会去检查是否有线程在排队，而是直接竞争锁
  - ReentrantLock
    - JDK提供的类
    - API层面的锁
    - 需要手动加锁与释放锁
    - 可获取当前是否上锁
    - 公平锁或者非公平锁
    - 可以中断
    - synchronized比较
      - JVM层面的锁
        -  JVM 的监视器锁（Monitor）机制，每个对象有一个监视器锁（monitor）
     -  
      - 自动加锁释放
      - 不可获取当前线程是否上锁
      - 非公平锁
      - 不可中断
      - 重量级锁
        - 监视器锁（monitor）是依赖于底层的操作系统的MutexLock来实现的、
    - 对于低竞争场景，由于synchronized 经过多次优化（如偏向锁、轻量级锁），一般与 ReentrantLock 相当甚至更好。
    - 对于高竞争场景，ReentrantLock 提供了更多的灵活性（如公平锁、可中断锁等），更适合复杂需求。

  - volatile
    - 关键字能保证数据的可见性，但不能保证数据的原子性。
    - 它的主要作用是告知编译器该变量可能会被多线程同时访问，因此不应对其进行重排序等优化操作。
    - 

- **线程池**
  - 这里推荐阅读线程池源码
  - 参数说明
    - 核心线程数量
    - 最大线程数量
    - 非核心线程的空间状态的存活时间
    - 时间单位（天、小时）
    - 工作队列（阻塞队列）
    - 线程工厂（创建线程）
    - 拒绝策略 
  - Excutores创建线程池的问题
    - 不适用高并发场景，阻塞队列不方便，容易OOM
    - 使用无界队列，允许创建大量线程，缺乏灵活性
    - 实现对开发者不透明，难以排查
  - 阻塞队列
    - ArrayBlockingQueue 有界队列  控制资源使用
    - LinkedBlockingQueue 无界队列  任务量较大
    - SynchronousQueue 不存储任务的队列 直接传递任务给线程的场景 高性能、快速响应的系统
    - PriorityBlockingQueue	无界	按优先级排序	需要优先级调度的场景
    - DelayQueue	无界	延迟执行任务	定时任务、缓存过期等场景
    - LinkedTransferQueue	无界	高效的移交操作	高吞吐量、高并发场景
  - 拒绝策略
    - 中止策略  直接抛出异常  终止任务提交
    - 调用者运行策略  直接用主线程执行
    - 丢弃策略  直接丢弃且不抛出异常
    - 丢弃最旧任务策略  丢弃任务队列中最旧的任务（即等待时间最久的任务）

- **调试与排错**
  - 


## 难点
- 构造一个好的类：使用设计模式（如单例、工厂模式）提高质量。
- 重构代码：遵循《重构：改善既有代码的设计》原则，优化结构。
- 代码具有良好的可读性：遵循Oracle Java编码规范，使用有意义的变量名和注释。
- 让并发串行执行：使用synchronized、ReentrantLock或CountDownLatch。
