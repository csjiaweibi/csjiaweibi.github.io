---
title: '我所理解的操作系统'
date: 2025-04-04
permalink: /posts/2025/04/blog-post-4/
tags:
  - cool posts
  - category1
  - category2
---


像字节、腾讯这些大厂的技术面试以及几乎所有公司的笔试都会考操作系统相关的问题。
工作中使用
    在实际使用缓存的时候，软件层次而言的缓存思想，则是源自数据库速度、Redis（内存中间件）速度、本地内存速度之间的不匹配；而在计算机存储层次结构设计中，我们也能发现同样的问题及缓存思想的使用：内存用于解决磁盘访问速度过慢的问题，CPU 用三级缓存缓解寄存器和内存之间的速度差异。它们面临的都是同一个问题（速度不匹配）和同一个思想，那么计算机先驱者在存储层次结构设计上对缓存性能的优化措施，同样也适用于软件层次缓存的性能优化。

并发、虚拟化、持久化    我们相信学习系统的唯一方法就是做（do）系统，即在真正的系统上解决具体的问题，或是编写和运行程序。
什么是操作系统
    操作系统本质上是一个运行在计算机上的软件程序 ，主要用于管理计算机硬件和软件资源。
    https://mp.weixin.qq.com/s/sfAsq2wXpRfXwc6XJIr5Ww

进程管理
    用户态和内核态
        用户态(User Mode) : 用户态运行的进程可以直接读取用户程序的数据，拥有较低的权限。当应用程序需要执行某些需要特殊权限的操作，例如读写磁盘、网络通信等，就需要向操作系统发起系统调用请求，进入内核态。
        内核态(Kernel Mode)：内核态运行的进程几乎可以访问计算机的任何资源包括系统的内存空间、设备、驱动程序等，不受限制，拥有非常高的权限。当操作系统接收到进程的系统调用请求时，就会从用户态切换到内核态，执行相应的系统调用，并将结果返回给进程，最后再从内核态切换回用户态。

    用户态切换到内核态的 3 种方式
        系统调用（Trap）：用户态进程 主动 要求切换到内核态的一种方式，主要是为了使用内核态才能做的事情比如读取磁盘资源。系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现。
        中断（Interrupt）：当外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。
        异常（Exception）：当 CPU 在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异的内核相关程序中，也就转到了内核态，比如缺页异常。
        在系统的处理上，中断和异常类似，都是通过中断向量表来找到相应的处理程序进行处理。区别在于，中断来自处理器外部，不是由任何一条专门的指令造成，而异常是执行当前指令的结果。
        这些系统调用按功能大致可分为如下几类：设备管理：完成设备（输入输出设备和外部存储设备等）的请求或释放，以及设备启动等功能。文件管理：完成文件的读、写、创建及删除等功能。进程管理：进程的创建、撤销、阻塞、唤醒，进程间的通信等功能。内存管理：完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。

    1.为什么要划分内核态和用户态？
        计算机系统引入内核态（Kernel Mode）和用户态（User Mode）的主要目的是保证系统安全性和稳定性，同时提高多任务处理的效率。具体来说，它主要解决了以下几个核心问题：
        (1)防止用户程序直接访问关键资源，保障系统安全
        在早期计算机系统中，所有程序都可以直接访问硬件资源（如内存、CPU、磁盘等）。如果一个程序出错或者被恶意攻击，可能会导致整个系统崩溃。因此，操作系统引入了特权级别：
        内核态（特权模式）：只有操作系统可以运行的模式，允许访问所有硬件资源。
        用户态（受限模式）：普通应用程序只能使用有限的指令，不能直接访问硬件，必须通过系统调用请求操作系统提供服务。
        (2)防止程序互相影响，提升系统稳定性
        如果所有程序都能随意修改内存，可能会导致程序之间相互干扰，甚至系统崩溃。
        通过用户态和内核态的隔离，即使某个用户程序崩溃，也不会影响整个系统的运行。
        (3)提供受控的硬件访问，提升系统可靠性
        例如，用户程序不能直接操作磁盘，而是通过操作系统提供的接口（如文件系统API）来间接访问，防止数据损坏。
        进程调度、内存管理等关键操作也必须在内核态执行，避免用户程序恶意篡改。
        (4)支持多任务，提高计算机的并发能力
        多任务系统需要调度多个进程，防止某个进程无限占用CPU，导致其他进程无法运行。
        通过内核态调度，系统可以控制进程的执行，确保资源合理分配。

    2.用户态和内核态如何管理地址空间？它们是如何隔离的？
        用户态地址空间管理：
        每个用户进程都有自己的虚拟地址空间，通常为 4GB（在 32 位系统）或更大（64 位系统）。
        用户态进程不能直接访问内核地址空间，否则会触发段错误（Segmentation Fault）。
        内核态地址空间管理：
        内核态通常拥有整个物理内存的访问权限，可以访问所有用户态进程的内存。
        在 Linux 内核 中，虚拟地址空间通常被划分为：
        用户空间（低地址，如 0x00000000 ~ 0xBFFFFFFF）
        内核空间（高地址，如 0xC0000000 ~ 0xFFFFFFFF）
        进程在用户态运行时，不能直接访问内核空间，必须通过系统调用（syscall）或内核 API 访问。这种地址空间隔离机制提供了安全性，防止用户态进程直接访问或篡改内核数据。

    线程进程协程的区别
        进程（Process） 是指计算机中正在运行的一个程序实例。举例：你打开的微信就是一个进程。
        线程（Thread） 也被称为轻量级进程，更加轻量。多个线程可以在同一个进程中同时执行，并且共享进程的资源比如内存空间、文件句柄、网络连接等。举例：你打开的微信里就有一个线程专门用来拉取别人发你的最新的消息。
        协程 一种用户态的轻量级线程 调度完全由用户程序控制，而不需要内核的参与 
        线程和进程是操作系统资源调度和任务执行的核心概念，一个进程可以包含多个线程，它们主要有4个区别。
        第一个是资源分配与独立性上的区别，
            首先，进程是操作系统资源分配的基本单位。每个进程拥有独立的内存空间（如堆、栈、代码段）、文件句柄等系统资源，进程之间相互隔离，一个进程崩溃不会直接影响其他进程。
            然而，线程是CPU调度的基本单位，属于进程内部的执行流。同一进程下的多个线程共享进程的内存和资源（如全局变量、文件描述符），这使得线程间通信更高效，但也需要开发者处理同步问题。

        第二个是创建与切换的开销上的区别，
            首先，进程的创建和销毁开销较大，因为需要分配或回收独立的内存、资源，上下文切换时需要保存和恢复整个进程的状态（如内存页表、寄存器）。
            然而，线程的创建和切换更轻量，因为线程共享进程的资源，上下文切换仅需保存线程私有数据（如栈、寄存器），因此多线程更适合需要频繁切换任务的场景。

        第三个是通信与同步机制上的区别，
            首先，进程间通信（IPC）需要复杂机制，例如管道、消息队列、共享内存等，由操作系统提供支持，通信效率较低。
            然而，线程间通信直接通过共享内存（如同一个进程的全局变量），但需通过锁（如synchronized）、信号量等机制保证同步，避免数据竞争。

        第四个是容错与并发性上的区别，
            首先，进程的独立性提高了系统稳定性，一个进程的崩溃通常不会影响其他进程，适合需要高可靠性的场景（例如浏览器多标签页使用多进程）。
            然而，线程的共享特性更适合高并发任务，例如Web服务器同时处理多个请求，但一个线程的错误可能导致整个进程终止。


    进程有哪几种状态?
        创建状态(new)：进程正在被创建，尚未到就绪状态。
        就绪状态(ready)：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
        运行状态(running)：进程正在处理器上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
        阻塞状态(waiting)：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
        结束状态(terminated)：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

    进程的调度算法有哪些
        先到先服务调度算法(FCFS，First Come, First Served) : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。适用于CPU繁忙型作业的系统，不适用于I/O 繁忙型作业的系统，适合于长作业，适合于短作业。
        短作业优先的调度算法(SJF，Shortest Job First) : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
        时间片轮转调度算法（RR，Round-Robin） : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
        多级反馈队列调度算法（MFQ，Multi-level Feedback Queue）：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程 。
            多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成，因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。

        优先级调度算法（Priority）：为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

    线程的调度算法有哪些
        线程调度策略主要有时间切片式和抢占式两种方式，不同的调度方式会影响线程的执行顺序和资源分配。
        时间切片式调度是一种公平调度策略，当一个进程中存在多个优先级相同的线程时，CPU会为每个线程分配固定的时间片，线程依次轮流执行。例如，线程1运行一段时间后挂起，CPU切换到线程2，再运行一段时间后切换到线程3，以此类推。这种方式可以保证所有线程都有机会获得CPU时间，但无法保证高优先级线程能立即执行。
        抢占式调度则是基于优先级进行线程调度，优先级高的线程更容易获得CPU的执行权，但并不意味着一定会被最先执行。操作系统通常会根据线程的优先级、等待时间和系统负载来决定具体的执行顺序，因此高优先级线程只是相对更容易被调度，而不是绝对优先执行。抢占式调度能够更好地满足实时性需求，适用于对任务优先级有严格要求的场景。

    进程间通信
        管道/匿名管道(Pipes) ：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。 「|」竖线就是匿名管道
            用于具有亲缘关系的进程间通信，数据采用先进先出（FIFO）的方式进行传输，通常用于父子进程或兄弟进程之间。
            当一个管道建立时，它会创建两个文件描述符：fd[0]为读而打开，fd[1]为写而打开，要关闭管道只需将这两个文件描述符关闭即可。单进程中的管道如下图：
            文件描述符（File Descriptor，简称FD）是操作系统中用于标识打开的文件的一个整数。在Linux系统中，一切皆文件，包括普通文件、目录、链接以及设备。文件描述符为操作系统提供了一个高效管理已打开文件的方式。每个进程都有一个文件描述符表，用于跟踪该进程打开的所有文件。

        有名管道(Named Pipes) : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循 先进先出(First In First Out) 。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。
        信号(Signal) ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；异步通信
        消息队列(Message Queuing) ：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺点。
        信号量(Semaphores) ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。
        共享内存(Shared memory) ：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。
        套接字(Sockets) : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

    线程间的同步的方式有哪些
        线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。
        下面是几种常见的线程同步的方式：
            互斥锁(Mutex) ：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
            读写锁（Read-Write Lock） ：允许多个线程同时读取共享资源，但只有一个线程可以对共享资源进行写操作。分为 读锁和 写锁  写锁是独占锁
            信号量(Semaphore) ：是一种计数器，它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
            屏障（Barrier） ：屏障是一种同步原语，用于等待多个线程到达某个点再一起继续执行。当一个线程到达屏障时，它会停止执行并等待其他线程到达屏障，直到所有线程都到达屏障后，它们才会一起继续执行。比如 Java 中的 CyclicBarrier 是这种机制。
            事件(Event) :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。
            自旋锁


    线程比进程高效的原因
        线程比进程高效的原因主要体现在资源共享、创建开销、上下文切换成本和并发执行效率上，接下来我将分别进行详细讲述。
        首先是线程的资源共享，
            进程是独立的，它们的地址空间、文件描述符等资源彼此隔离，进程间通信（IPC）需要额外的机制，如管道、消息队列、共享内存等，这些都带来了较大的通信开销。而线程则共享进程的资源，多个线程可以直接访问相同的变量、堆空间等。线程间的通信效率更高，不需要额外的IPC机制，因此线程在资源共享上比进程更高效。

        然后是线程的创建开销更小，
            创建进程时，操作系统需要为其分配独立的内存空间，加载程序、初始化资源，这些步骤较为复杂且资源消耗大。而创建线程时，线程共享进程的资源，因此只需要为其分配一个栈空间，创建的成本远小于进程。线程的创建开销比进程小，因此在需要频繁创建和销毁执行单元的场景下，线程更具优势。

        其次是线程的上下文切换开销更低，
            进程切换时，操作系统需要保存和恢复完整的寄存器状态、页表、文件描述符等，涉及更多的CPU计算和内存操作，因此进程的上下文切换开销较大。而线程切换仅涉及寄存器和栈指针的切换，不需要进行地址空间的转换，开销远小于进程切换。因此，线程的上下文切换更加高效。

        最后是线程的并发执行效率更高，
            在多核处理器上，多个线程可以在不同的核心上并行执行，有效提高程序的执行效率。由于线程共享进程资源，它们之间的通信和数据交换更加高效，减少了跨进程的资源访问开销。而进程由于资源的隔离，通常无法像线程那样充分利用多核资源，因此进程的并发执行效率相对较低。


    卖家宣传CPU是6核12线程，那么Java是最多只能创建12个线程嘛
        不受CPU限制，Java线程数主要受限于，JVM内存（每个线程默认分配1MB栈空间），操作系统限制（Windows默认约2000线程，Linux约32000线程）。
        操作系统快速切换线程（时间片通常15ms），制造"同时运行"的假象，实际上执行的线程数 ≤ CPU线程数（12线程）。
        示例计算：
        // 假设堆内存4GB，每个线程栈1MB最大线程数 ≈ (4GB堆内存) / (1MB/线程) = 4096线程

    异步编程与线程结合的好处
        异步编程通过将任务分解为小的非阻塞操作，能够有效减少等待时间，提高系统的响应性。与线程结合时，异步编程可以：
        减少线程阻塞，异步操作通常在 I/O 密集型任务中使用，线程可以在等待 I/O 操作的同时，执行其他任务，从而避免线程阻塞。
        提高资源利用率，通过事件循环机制（如 Node.js 的异步事件模型），多个异步任务可以在少数线程中并发执行，极大地提高了资源的利用率。
        这种方式特别适用于网络请求、文件读写等 I/O 密集型操作，而对于 CPU 密集型操作，线程仍然能够提供较高的并发性能。

    线程与进程
        僵尸进程和孤儿进程
            僵尸进程：子进程已经终止，但是其父进程仍在运行，且父进程没有调用 wait()或 waitpid()等系统调用来获取子进程的状态信息，释放子进程占用的资源，导致子进程的 PCB 依然存在于系统中，但无法被进一步使用。这种情况下，子进程被称为“僵尸进程”。避免僵尸进程的产生，父进程需要及时调用 wait()或 waitpid()系统调用来回收子进程。
            孤儿进程：一个进程的父进程已经终止或者不存在，但是该进程仍在运行。这种情况下，该进程就是孤儿进程。孤儿进程通常是由于父进程意外终止或未及时调用 wait()或 waitpid()等系统调用来回收子进程导致的。为了避免孤儿进程占用系统资源，操作系统会将孤儿进程的父进程设置为 init 进程（进程号为 1），由 init 进程来回收孤儿进程的资源。


    死锁
        产生死锁的四个必要条件是什么?
            互斥：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。占有并等待：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。非抢占：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。破坏第三个条件 非抢占：也就是说可以采用 剥夺式调度算法，但剥夺式调度方法目前一般仅适用于 主存资源 和 处理器资源 的分配，并不适用于所有的资源，会导致 资源利用率下降。循环等待：有一组等待进程 {P0, P1,..., Pn}， P0 等待的资源被 P1 占有，P1 等待的资源被 P2 占有，……，Pn-1 等待的资源被 Pn 占有，Pn 等待的资源被 P0 占有。

        解决死锁的方法可以从多个角度去分析
            一般的情况下，有预防，避免，检测和解除四种。
            预防 是采用某种策略，限制并发进程对资源的请求，从而使得死锁的必要条件在系统执行的任何时间上都不满足。  导致 低效的进程运行 和 资源使用率 避免则是系统在分配资源时，根据资源的使用情况提前做出预测，从而避免死锁的发生那么如何保证系统保持在安全状态呢？通过算法，其中最具有代表性的 避免死锁算法 就是 Dijkstra 的银行家算法，银行家算法用一句话表达就是：当一个进程申请使用资源的时候，银行家算法 通过先 试探 分配给该进程资源，然后通过 安全性算法 判断分配后系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待，若能够进入到安全的状态，则就 真的分配资源给该进程。检测是指系统设有专门的机构，当死锁发生时，该机构能够检测死锁的发生，并精确地确定与死锁有关的进程和资源。   乐观锁  系统 定时地运行一个 “死锁检测” 的程序（有环无环），判断系统内是否出现死锁，如果检测到系统发生了死锁，再采取措施去解除它。解除是与检测相配套的一种措施，用于将进程从死锁状态下解脱出来。
            1.一个线程尽量值获取一个锁，占用一个资源；
            2.使用定时锁替代内部锁；
            3.数据库锁的加锁和解锁必须在一个数据库连接；



内存管理
    管理工作
        内存的分配与回收
            对进程所需的内存进行分配和释放内存

        地址转换
            将程序中的虚拟地址转换成内存中的物理地址。

        内存扩充
            当系统没有足够的内存时，利用虚拟内存技术或自动覆盖技术，从逻辑上扩充内存。

        内存映射
            将一个文件直接映射到进程的进程空间中，这样可以通过内存指针用读写内存的办法直接存取文件内容，速度更快。

        内存优化
            通过调整内存分配策略和回收算法来优化内存使用效率。

        内存安全
            保证进程之间使用内存互不干扰，避免一些恶意程序通过修改内存来破坏系统的安全性。


    管理方式
        连续内存管理
            为一个用户程序分配一个连续的内存空间，内存利用率一般不高。  伙伴系统算法

        非连续内存管理
            允许一个程序使用的内存分布在离散或者说不相邻的内存中，相对更加灵活一些。

        段式管理
            以段(一段连续的物理内存)的形式管理/分配物理内存。应用程序的虚拟地址空间被分为大小不等的段，段是有实际意义的，每个段定义了一组逻辑信息，例如有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。

        页式管理
            把物理内存分为连续等长的物理页，应用程序的虚拟地址空间也被划分为连续等长的虚拟页，是现代操作系统广泛使用的一种内存管理方式。

        段页式管理机制
            结合了段式管理和页式管理的一种内存管理机制，把物理内存先分成若干段，每个段又继续分成若干大小相等的页。


    虚拟内存
        是计算机系统内存管理非常重要的一个技术，本质上来说它只是逻辑存在的，是一个假想出来的内存空间，主要作用是作为进程访问主存（物理内存）的桥梁并简化内存管理。
        作用
            隔离进程：物理内存通过虚拟地址空间访问，虚拟地址空间与进程一一对应。每个进程都认为自己拥有了整个物理内存，进程之间彼此隔离，一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。
            提升物理内存利用率：有了虚拟地址空间后，操作系统只需要将进程当前正在使用的部分数据或指令加载入物理内存。
            简化内存管理：进程都有一个一致且私有的虚拟地址空间，程序员不用和真正的物理内存打交道，而是借助虚拟地址空间访问物理内存，从而简化了内存管理。
            多个进程共享物理内存：进程在运行过程中，会加载许多操作系统的动态库。这些库对于每个进程而言都是公用的，它们在内存中实际只会加载一份，这部分称为共享内存。
            提高内存使用安全性：控制进程对物理内存的访问，隔离不同进程的访问权限，提高系统的安全性。
            提供更大的可使用内存空间：可以让程序拥有超过系统物理内存大小的可用内存空间。这是因为当物理内存不够用时，可以利用磁盘充当，将物理内存页（通常大小为 4 KB）保存到磁盘文件（会影响读写速度），数据或代码页会根据需要在物理内存与磁盘之间移动。

        与物理地址的转换
            操作系统一般通过 CPU 芯片中的一个重要组件 MMU(Memory Management Unit，内存管理单元) 将虚拟地址转换为物理地址，这个过程被称为 地址翻译/地址转换（Address Translation） 
            通过 MMU 将虚拟地址转换为物理地址后，再通过总线传到物理内存设备，进而完成相应的物理内存读写请求
            MMU 将虚拟地址翻译为物理地址的主要机制有两种: 分段机制 和 分页机制 。

        分段机制
            分段机制（Segmentation） 以段(一段连续的物理内存)的形式管理/分配物理内存。应用程序的虚拟地址空间被分为大小不等的段，段是有实际意义的，每个段定义了一组逻辑信息，例如有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。
            分段管理通过 段表（Segment Table） 映射虚拟地址和物理地址。分段机制下的虚拟地址由两部分组成：段号：标识着该虚拟地址属于整个虚拟地址空间中的哪一个段。段内偏移量：相对于该段起始地址的偏移量。具体的地址翻译过程如下：MMU 首先解析得到虚拟地址中的段号；通过段号去该应用程序的段表中取出对应的段信息（找到对应的段表项）；从段信息中取出该段的起始地址（物理地址）加上虚拟地址中的段内偏移量得到最终的物理地址。

        分页机制
            分页机制（Paging） 把主存（物理内存）分为连续等长的物理页，应用程序的虚拟地址空间划也被分为连续等长的虚拟页。现代操作系统广泛采用分页机制。注意：这里的页是连续等长的，不同于分段机制下不同长度的段。在分页机制下，应用程序虚拟地址空间中的任意虚拟页可以被映射到物理内存中的任意物理页上，因此可以实现物理内存资源的离散分配。分页机制按照固定页大小分配物理内存，使得物理内存资源易于管理，可有效避免分段机制中外部内存碎片的问题。
            多级页表属于时间换空间的典型场景，利用增加页表查询的次数减少页表占用的空间
            转址旁路缓存(Translation Lookaside Buffer，TLB，也被称为快表
                在主流的 AArch64 和 x86-64 体系结构下，TLB 属于 (Memory Management Unit，内存管理单元) 内部的单元，本质上就是一块高速缓存（Cache），缓存了虚拟页号到物理页号的映射关系，你可以将其简单看作是存储着键（虚拟页号）值（物理页号）对的哈希表。



    局部性原理
        局部性原理是指在程序执行过程中，数据和指令的访问存在一定的空间和时间上的局部性特点。其中，时间局部性是指一个数据项或指令在一段时间内被反复使用的特点，空间局部性是指一个数据项或指令在一段时间内与其相邻的数据项或指令被反复使用的特点。在分页机制中，页表的作用是将虚拟地址转换为物理地址，从而完成内存访问。
        在这个过程中，局部性原理的作用体现在两个方面：
            时间局部性：由于程序中存在一定的循环或者重复操作，因此会反复访问同一个页或一些特定的页，这就体现了时间局部性的特点。为了利用时间局部性，分页机制中通常采用缓存机制来提高页面的命中率，即将最近访问过的一些页放入缓存中，如果下一次访问的页已经在缓存中，就不需要再次访问内存，而是直接从缓存中读取。
            空间局部性：由于程序中数据和指令的访问通常是具有一定的空间连续性的，因此当访问某个页时，往往会顺带访问其相邻的一些页。为了利用空间局部性，分页机制中通常采用预取技术来预先将相邻的一些页读入内存缓存中，以便在未来访问时能够直接使用，从而提高访问速度。总之，局部性原理是计算机体系结构设计的重要原则之一，也是许多优化算法的基础。在分页机制中，利用时间局部性和空间局部性，采用缓存和预取技术，可以提高页面的命中率，从而提高内存访问效率



文件管理
    功能
        存储管理：将文件数据存储到物理存储介质中，并且管理空间分配，以确保每个文件都有足够的空间存储，并避免文件之间发生冲突。
        文件管理：文件的创建、删除、移动、重命名、压缩、加密、共享等等。
        目录管理：目录的创建、删除、移动、重命名等等。
        文件访问控制：管理不同用户或进程对文件的访问权限，以确保用户只能访问其被授权访问的文件，以保证文件的安全性和保密性。

    磁盘调度算法有哪些
        磁盘调度算法是操作系统中对磁盘访问请求进行排序和调度的算法，其目的是提高磁盘的访问效率。一次磁盘读写操作的时间由磁盘寻道/寻找时间、延迟时间和传输时间决定。磁盘调度算法可以通过改变到达磁盘请求的处理顺序，减少磁盘寻道时间和延迟时间。常见的磁盘调度算法有下面这 6 种（其他还有很多磁盘调度算法都是基于这些算法改进得来的）：


输入输出（I/O）管理
    I/o模型


Linux
    怎么学
        试着去成为一个有 CS 梦想的人
        是一个合格的操作系统用户
            会 STFW/RTFM/ATFAI 自己动手解决问题
            进而，不怕使用任何命令行工具
                vim, tmux, grep, gcc, binutils, ...


        不怕 (或者爱上) 写代码
            能管理一定规模 (数千行) 的代码
            在出 bug 时默念 “机器永远是对的、我肯定能调出来的”
                然后开始用正确的工具/方法调试



    操作系统 
        why ? what ? how ? 
        基本动机
            更快更好地服务更多应用

        基本方法
            buliding abtratcions

        里程碑 与弯路
            Unix  , Linux

        目的：应用、创新、革命

    如何查看系统日志文件?
        常见的系统日志文件有哪些?
        查看日志：使用cat、tail、less等命令查看日志文件，如/var/log/syslog、/var/log/messages等。
        常见日志文件：/var/log/syslog：系统日志。/var/log/auth.log：认证日志。/var/log/kern.log：内核日志。/var/log/dmesg：启动日志。

    Linux语法
        在Linux Shell中变量赋值时,等号"="两边不能有空格,这是Shell的语法规则
        grep命令用于文本搜索,其中 -v 参数表示反向匹配(显示不匹配的行)
        ^$ 是正则表达式,表示空行(^ 表示行首,$ 表示行尾,连在一起就表示一行中没有任何字符)

    Linux文件权限
        rwx：读（r）、写（w）、执行（x）权限，分别对应用户、组、其他。

    Linux查看内存占用命令
        free -h、top、htop。

    Linux查进程的命令
        ps：查看当前进程状态，如ps aux。top：实时查看系统进程和资源占用。htop：增强版的top，支持交互操作。pgrep：根据名称查找进程ID，如pgrep java。

    什么是软链接和硬链接?
        它们之间有什么区别?软链接（Symbolic Link）：类似于快捷方式，指向另一个文件或目录的路径。删除源文件后，软链接失效。硬链接（Hard Link）：直接指向文件的inode，与源文件共享相同的数据块。删除源文件后，硬链接仍然有效。区别：软链接可以跨文件系统，硬链接不能。软链接可以指向目录，硬链接不能。删除源文件对软链接和硬链接的影响不同。


