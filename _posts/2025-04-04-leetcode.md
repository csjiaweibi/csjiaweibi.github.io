---
title: '我所理解的算法'
date: 2025-04-04
permalink: /posts/2025/04/blog-post-2/
tags:
  - cool posts
---

本文基于hot100

算法

# 思想
数据结构 = 算法 +数据结构

所有的题目都是为了搜索，更快更好的搜索

# 数据结构
数据结构 :  数组 链表 树 图

数组 : 动态数组  静态数组

链表 : 双向链表  单向链表  循环链表

树 : 二叉树 平衡搜索树 满二叉树 红黑树 B+树

图 : 有向图 无向图

# 算法
算法思想 : 双指针 动态规划 滑动窗口 回溯 贪心 并查集 迪杰斯特拉算法 深度优先搜索 堆排序  广度优先搜索 模拟 前缀和



# ACM算法历程




考过的题  （临时复习）
    快速排序

    堆排序

    求子数组的最小值之和
    重排链表
    判断链表是否有环
        值相等还是链表节点相等
        代码不够整洁 需要重构

    爬楼梯
    完全平方数
    链表k个翻转
    模拟输出题
    接雨水
    复习八股要以题目出发
        饿了么  3.14
            选择题很麻烦 混着两道行测一起考 考的非常细 很难准备
            操作系统 linux 权限 都考了  也考了sql的具体语法细节 
            编程题
                签到题很简单
                回溯算法   有特例没想出来 
                简单题  有点可惜 感觉题目的难度和顺序不一样


        作业帮  3.6
            解析网页题
            解析字符串题
            难题

        美团 3.14
            模拟
            搜索
            生成树 联通图
            重复元素 链表

        淘天3.22
        阿里云3.30
        蚂蚁3.30


LeetCode Hot100   剑指Offer 多刷几遍
    LC周赛稳定出三道即可！！
    难度:高于hot 100，三道题，出两道hard的不少见阿里系、米哈游、华为、字节

数据结构抽象
    了解 Redis 数据库的朋友可能也知道，Redis 提供列表、字符串、集合等等几种常用数据结构，但是对于每种数据结构，底层的存储方式都至少有两种，以便于根据存储数据的实际情况使用合适的存储方式。
    同一种逻辑结构可采用不同的存储结构
    算法的设计取决于选定的逻辑结构，而算法的实现依赖于采用的存储结构
    如何遍历 + 访问？
        各种数据结构的遍历 + 访问无非两种形式：线性的和非线性的。

    数字编码
        原码、反码和补码
            所有整数类型能够表示的负数都比正数多一个
            首先需要指出，数字是以“补码”的形式存储在计算机中的。在分析这样做的原因之前，我们首先给出三者的定义：
            原码：我们将数字的二进制表示的最高位视为符号位，其中 0 表示正数，1 表示负数，其余位表示数字的值。
                「原码 true form」虽然最直观，但存在一些局限性。一方面，负数的原码不能直接用于运算
                另一方面，数字零的原码有 +0 和 −0 两种表示方式。这意味着数字零对应着两个不同的二进制编码，其可能会带来歧义。比如在条件判断中，如果没有区分正零和负零，则可能会导致判断结果出错。而如果我们想要处理正零和负零歧义，则需要引入额外的判断操作，其可能会降低计算机的运算效率。
                与原码一样，反码也存在正负零歧义问题，因此计算机进一步引入了「补码 2's complement code」。

            反码：正数的反码与其原码相同，负数的反码是对其原码除符号位外的所有位取反。
                为了解决此问题，计算机引入了「反码 1's complement code」。如果我们先将原码转换为反码，并在反码下计算 1+(−2) ，最后将结果从反码转化回原码，则可得到正确结果 −1 。

            补码：正数的补码与其原码相同，负数的补码是在其反码的基础上加 1 。
                与原码一样，反码也存在正负零歧义问题，因此计算机进一步引入了「补码 2's complement code」。
                然而，补码 1000 0000 是一个例外，它并没有对应的原码。根据转换方法，我们得到该补码的原码为 0000 0000 。这显然是矛盾的，因为该原码表示数字 0 ，它的补码应该是自身。计算机规定这个特殊的补码 1000 0000 代表 −128 。实际上，(−1)+(−127) 在补码下的计算结果就是 −128 。
                你可能已经发现，上述的所有计算都是加法运算。这暗示着一个重要事实：计算机内部的硬件电路主要是基于加法运算设计的。这是因为加法运算相对于其他运算（比如乘法、除法和减法）来说，硬件实现起来更简单，更容易进行并行化处理，运算速度更快。

            现在我们可以总结出计算机使用补码的原因：基于补码表示，计算机可以用同样的电路和操作来处理正数和负数的加法，不需要设计特殊的硬件电路来处理减法，并且无须特别处理正负零的歧义问题。这大大简化了硬件设计，提高了运算效率。

        浮点数编码
            细心的你可能会发现：int 和 float 长度相同，都是 4 bytes，但为什么 float 的取值范围远大于 int ？这非常反直觉，因为按理说 float 需要表示小数，取值范围应该变小才对。
            实际上，这是因为浮点数 float 采用了不同的表示方式。记一个 32-bit 长度的二进制数为：
                �31�30�29…�2�1�0

            根据 IEEE 754 标准，32-bit 长度的 float 由以下部分构成：
            符号位 S ：占 1 bit ，对应 31 。
            指数位 E ：占 8 bits ，对应 30�29…�23 。
            分数位 N ：占 23 bits ，对应 �22�21…�0 。

            现在我们可以回答最初的问题：float 的表示方式包含指数位，导致其取值范围远大于 int 
            尽管浮点数 float 扩展了取值范围，但其副作用是牺牲了精度。整数类型 int 将全部 32 位用于表示数字，数字是均匀分布的；而由于指数位的存在，浮点数 float 的数值越大，相邻两个数字之间的差值就会趋向越大。


    字符编码
        在计算机中，所有数据都是以二进制数的形式存储的，字符 char 也不例外。为了表示字符，我们需要建立一套“字符集”，规定每个字符和二进制数之间的一一对应关系。有了字符集之后，计算机就可以通过查表完成二进制数到字符的转换。
        ASCII 字符集
            「ASCII 码」是最早出现的字符集，全称为“美国标准信息交换代码”。它使用 7 位二进制数（即一个字节的低 7 位）表示一个字符，最多能够表示 128 个不同的字符。如图 3-6 所示，ASCII 码包括英文字母的大小写、数字 0-9 、一些标点符号，以及一些控制字符（如换行符和制表符）。
            然而，ASCII 码仅能够表示英文。随着计算机的全球化，诞生了一种能够表示更多语言的字符集「EASCII」。它在 ASCII 的 7 位基础上扩展到 8 位，能够表示 256 个不同的字符。
            在世界范围内，陆续出现了一批适用于不同地区的 EASCII 字符集。这些字符集的前 128 个字符统一为 ASCII 码，后 128 个字符定义不同，以适应不同语言的需求。

        GBK 字符集
            后来人们发现，EASCII 码仍然无法满足许多语言的字符数量要求。比如汉字大约有近十万个，光日常使用的就有几千个。中国国家标准总局于 1980 年发布了「GB2312」字符集，其收录了 6763 个汉字，基本满足了汉字的计算机处理需要。
            然而，GB2312 无法处理部分的罕见字和繁体字。「GBK」字符集是在 GB2312 的基础上扩展得到的，它共收录了 21886 个汉字。在 GBK 的编码方案中，ASCII 字符使用一个字节表示，汉字使用两个字节表示。

        Unicode 字符集
            随着计算机的蓬勃发展，字符集与编码标准百花齐放，而这带来了许多问题。一方面，这些字符集一般只定义了特定语言的字符，无法在多语言环境下正常工作。另一方面，同一种语言也存在多种字符集标准，如果两台电脑安装的是不同的编码标准，则在信息传递时就会出现乱码。
            那个时代的研究人员就在想：如果推出一个足够完整的字符集，将世界范围内的所有语言和符号都收录其中，不就可以解决跨语言环境和乱码问题了吗？在这种想法的驱动下，一个大而全的字符集 Unicode 应运而生。
            「Unicode」的全称为“统一字符编码”，理论上能容纳一百多万个字符。它致力于将全球范围内的字符纳入到统一的字符集之中，提供一种通用的字符集来处理和显示各种语言文字，减少因为编码标准不同而产生的乱码问题。
            自 1991 年发布以来，Unicode 不断扩充新的语言与字符。截止 2022 年 9 月，Unicode 已经包含 149186 个字符，包括各种语言的字符、符号、甚至是表情符号等。在庞大的 Unicode 字符集中，常用的字符占用 2 字节，有些生僻的字符占 3 字节甚至 4 字节。
            Unicode 是一种字符集标准，本质上是给每个字符分配一个编号（称为“码点”），但它并没有规定在计算机中如何存储这些字符码点。我们不禁会问：当多种长度的 Unicode 码点同时出现在同一个文本中时，系统如何解析字符？例如给定一个长度为 2 字节的编码，系统如何确认它是一个 2 字节的字符还是两个 1 字节的字符？
            对于以上问题，一种直接的解决方案是将所有字符存储为等长的编码。如图 3-7 所示，“Hello”中的每个字符占用 1 字节，“算法”中的每个字符占用 2 字节。我们可以通过高位填 0 ，将“Hello 算法”中的所有字符都编码为 2 字节长度。这样系统就可以每隔 2 字节解析一个字符，恢复出这个短语的内容了。

        UTF-8 编码
            目前，UTF-8 已成为国际上使用最广泛的 Unicode 编码方法。它是一种可变长的编码，使用 1 到 4 个字节来表示一个字符，根据字符的复杂性而变。ASCII 字符只需要 1 个字节，拉丁字母和希腊字母需要 2 个字节，常用的中文字符需要 3 个字节，其他的一些生僻字符需要 4 个字节。
            UTF-8 的编码规则并不复杂，分为两种情况：
                对于长度为 1 字节的字符，将最高位设置为 0 、其余 7 位设置为 Unicode 码点。值得注意的是，ASCII 字符在 Unicode 字符集中占据了前 128 个码点。也就是说，UTF-8 编码可以向下兼容 ASCII 码。这意味着我们可以使用 UTF-8 来解析年代久远的 ASCII 码文本。
                对于长度为 n字节的字符（其中  n>1），将首个字节的高  n位都设置为 1 、第 n+1 位设置为 0 ；从第二个字节开始，将每个字节的高 2 位都设置为 10 ；其余所有位用于填充字符的 Unicode 码点。

            图 3-8 展示了“Hello算法”对应的 UTF-8 编码。观察发现，由于最高 � 位都被设置为 1 ，因此系统可以通过读取最高位 1 的个数来解析出字符的长度为 � 。
            但为什么要将其余所有字节的高 2 位都设置为 10 呢？实际上，这个 10 能够起到校验符的作用。假设系统从一个错误的字节开始解析文本，字节头部的 10 能够帮助系统快速的判断出异常。
            之所以将 10 当作校验符，是因为在 UTF-8 编码规则下，不可能有字符的最高两位是 10 。这个结论可以用反证法来证明：假设一个字符的最高两位是 10 ，说明该字符的长度为 1 ，对应 ASCII 码。而 ASCII 码的最高位应该是 0 ，与假设矛盾。
                  UTF-8 编码示例

            除了 UTF-8 之外，常见的编码方式还包括：
                UTF-16 编码：使用 2 或 4 个字节来表示一个字符。所有的 ASCII 字符和常用的非英文字符，都用 2 个字节表示；少数字符需要用到 4 个字节表示。对于 2 字节的字符，UTF-16 编码与 Unicode 码点相等。
                UTF-32 编码：每个字符都使用 4 个字节。这意味着 UTF-32 会比 UTF-8 和 UTF-16 更占用空间，特别是对于 ASCII 字符占比较高的文本。

            从存储空间的角度看，使用 UTF-8 表示英文字符非常高效，因为它仅需 1 个字节；使用 UTF-16 编码某些非英文字符（例如中文）会更加高效，因为它只需要 2 个字节，而 UTF-8 可能需要 3 个字节。
            从兼容性的角度看，UTF-8 的通用性最佳，许多工具和库都优先支持 UTF-8 。

        编程语言的字符编码
            对于以往的大多数编程语言，程序运行中的字符串都采用 UTF-16 或 UTF-32 这类等长的编码。这是因为在等长编码下，我们可以将字符串看作数组来处理，其优点包括：
                随机访问: UTF-16 编码的字符串可以很容易地进行随机访问。UTF-8 是一种变长编码，要找到第 i个字符，我们需要从字符串的开始处遍历到第 i 个字符，这需要 O(n) 的时间。
                字符计数: 与随机访问类似，计算 UTF-16 字符串的长度也是 O(1) 的操作。但是，计算 UTF-8 编码的字符串的长度需要遍历整个字符串。
                字符串操作: 在 UTF-16 编码的字符串中，很多字符串操作（如分割、连接、插入、删除等）都更容易进行。在 UTF-8 编码的字符串上进行这些操作通常需要额外的计算，以确保不会产生无效的 UTF-8 编码。

            实际上，编程语言的字符编码方案设计是一个很有趣的话题，其涉及到许多因素：
            Java 的 String 类型使用 UTF-16 编码，每个字符占用 2 字节。这是因为 Java 语言设计之初，人们认为 16 位足以表示所有可能的字符。然而，这是一个不正确的判断。后来 Unicode 规范扩展到了超过 16 位，所以 Java 中的字符现在可能由一对 16 位的值（称为“代理对”）表示。
            JavaScript 和 TypeScript 的字符串使用 UTF-16 编码的原因与 Java 类似。当 JavaScript 语言在 1995 年被 Netscape 公司首次引入时，Unicode 还处于相对早期的阶段，那时候使用 16 位的编码就足够表示所有的 Unicode 字符了。
            C# 使用 UTF-16 编码，主要因为 .NET 平台是由 Microsoft 设计的，而 Microsoft 的很多技术，包括 Windows 操作系统，都广泛地使用 UTF-16 编码。
            由于以上编程语言对字符数量的低估，它们不得不采取“代理对”的方式来表示超过 16 位长度的 Unicode 字符。这是一个不得已为之的无奈之举。一方面，包含代理对的字符串中，一个字符可能占用 2 字节或 4 字节，从而丧失了等长编码的优势。另一方面，处理代理对需要增加额外代码，这增加了编程的复杂性和 Debug 难度。
            出于以上原因，部分编程语言提出了不同的编码方案：
            Python 3 使用一种灵活的字符串表示，存储的字符长度取决于字符串中最大的 Unicode 码点。对于全部是 ASCII 字符的字符串，每个字符占用 1 个字节；如果字符串中包含的字符超出了 ASCII 范围，但全部在基本多语言平面（BMP）内，每个字符占用 2 个字节；如果字符串中有超出 BMP 的字符，那么每个字符占用 4 个字节。
            Go 语言的 string 类型在内部使用 UTF-8 编码。Go 语言还提供了 rune 类型，它用于表示单个 Unicode 码点。
            Rust 语言的 str 和 String 类型在内部使用 UTF-8 编码。Rust 也提供了 char 类型，用于表示单个 Unicode 码点。
            需要注意的是，以上讨论的都是字符串在编程语言中的存储方式，这和字符串如何在文件中存储或在网络中传输是两个不同的问题。在文件存储或网络传输中，我们通常会将字符串编码为 UTF-8 格式，以达到最优的兼容性和空间效率。
            越“新”的语言考虑的越全面，因为历史包袱少

        为什么哈希表同时包含线性数据结构和非线性数据结构？
            哈希表底层是数组，而为了解决哈希冲突，我们可能会使用“链式地址”（后续哈希表章节会讲）。在拉链法中，数组中每个地址（桶）指向一个链表；当这个链表长度超过一定阈值时，又可能被转化为树（通常为红黑树）。因此，哈希表可能同时包含线性（数组、链表）和非线性（树）数据结构。

        char 类型的长度是 1 byte 吗？
            char 类型的长度由编程语言采用的编码方法决定。例如，Java, JS, TS, C# 都采用 UTF-16 编码（保存 Unicode 码点），因此 char 类型的长度为 2 bytes 。


    哈希表
        「哈希表 hash table」，又称「散列表」，其通过建立键 key 与值 value 之间的映射，实现高效的元素查询。具体而言，我们向哈希表输入一个键 key ，则可以在 O(1) 时间内获取对应的值 value 。
            观察发现，在哈希表中进行增删查改的时间复杂度都是 O(1) ，非常高效。

        哈希表简单实现
            我们先考虑最简单的情况，仅用一个数组来实现哈希表。在哈希表中，我们将数组中的每个空位称为「桶 bucket」，每个桶可存储一个键值对。因此，查询操作就是找到 key 对应的桶，并在桶中获取 value 。
            那么，如何基于 key 来定位对应的桶呢？这是通过「哈希函数 hash function」实现的。哈希函数的作用是将一个较大的输入空间映射到一个较小的输出空间。在哈希表中，输入空间是所有 key ，输出空间是所有桶（数组索引）。换句话说，输入一个 key ，我们可以通过哈希函数得到该 key 对应的键值对在数组中的存储位置。
            输入一个 key ，哈希函数的计算过程分为两步：
                通过某种哈希算法 hash() 计算得到哈希值。
                将哈希值对桶数量（数组长度）capacity 取模，从而获取该 key 对应的数组索引 index 。
                index = hash(key) % capacity

            随后，我们就可以利用 index 在哈希表中访问对应的桶，从而获取 value 。
            设数组长度 capacity = 100 、哈希算法 hash(key) = key ，易得哈希函数为 key % 100 。图 6-2 以 key 学号和 value 姓名为例，展示了哈希函数的工作原理。

        哈希冲突与扩容
            本质上看，哈希函数的作用是将所有 key 构成的输入空间映射到数组所有索引构成的输出空间，而输入空间往往远大于输出空间。因此，理论上一定存在“多个输入对应相同输出”的情况。
            对于上述示例中的哈希函数，当输入的 key 后两位相同时，哈希函数的输出结果也相同。例如，查询学号为 12836 和 20336 的两个学生时，我们得到：
            12836 % 100 = 3620336 % 100 = 36
            如图 6-3 所示，两个学号指向了同一个姓名，这显然是不对的。我们将这种多个输入对应同一输出的情况称为「哈希冲突 hash collision」。
            容易想到，哈希表容量 n 越大，多个 key 被分配到同一个桶中的概率就越低，冲突就越少。因此，我们可以通过扩容哈希表来减少哈希冲突。
            如图 6-4 所示，扩容前键值对 (136, A) 和 (236, D) 发生冲突，扩容后冲突消失。
            类似于数组扩容，哈希表扩容需将所有键值对从原哈希表迁移至新哈希表，非常耗时。并且由于哈希表容量 capacity 改变，我们需要通过哈希函数来重新计算所有键值对的存储位置，这进一步提高了扩容过程的计算开销。为此，编程语言通常会预留足够大的哈希表容量，防止频繁扩容。
            「负载因子 load factor」是哈希表的一个重要概念，其定义为哈希表的元素数量除以桶数量，用于衡量哈希冲突的严重程度，也常被作为哈希表扩容的触发条件。例如在 Java 中，当负载因子超过 0.75 时，系统会将哈希表容量扩展为原先的 2 倍。

        哈希冲突
            上节提到，通常情况下哈希函数的输入空间远大于输出空间，因此理论上哈希冲突是不可避免的。比如，输入空间为全体整数，输出空间为数组容量大小，则必然有多个整数映射至同一数组索引。
            哈希冲突会导致查询结果错误，严重影响哈希表的可用性。为解决该问题，我们可以每当遇到哈希冲突时就进行哈希表扩容，直至冲突消失为止。此方法简单粗暴且有效，但效率太低，因为哈希表扩容需要进行大量的数据搬运与哈希值计算。为了提升效率，我们切换一下思路：
            改良哈希表数据结构，使得哈希表可以在存在哈希冲突时正常工作。
            仅在必要时，即当哈希冲突比较严重时，才执行扩容操作。
            哈希表的结构改良方法主要包括链式地址和开放寻址。
                 链式地址
                    在原始哈希表中，每个桶仅能存储一个键值对。「链式地址 separate chaining」将单个元素转换为链表，将键值对作为链表节点，将所有发生冲突的键值对都存储在同一链表中。图 6-5 展示了一个链式地址哈希表的例子。
                    链式地址下，哈希表的操作方法包括：
                        查询元素：输入 key ，经过哈希函数得到数组索引，即可访问链表头节点，然后遍历链表并对比 key 以查找目标键值对。
                        添加元素：先通过哈希函数访问链表头节点，然后将节点（即键值对）添加到链表中。
                        删除元素：根据哈希函数的结果访问链表头部，接着遍历链表以查找目标节点，并将其删除。

                    该方法存在一些局限性，包括：
                        占用空间增大，链表包含节点指针，它相比数组更加耗费内存空间。
                        查询效率降低，因为需要线性遍历链表来查找对应元素。

                    以下给出了链式地址哈希表的简单实现，需要注意：
                        为了使得代码尽量简短，我们使用列表（动态数组）代替链表。在这种设定下，哈希表（数组）包含多个桶，每个桶都是一个列表。
                        以下代码实现了哈希表扩容方法。具体来看，当负载因子超过 0.75 时，我们将哈希表扩容至 2 倍。


                开放寻址
                    「开放寻址 open addressing」不引入额外的数据结构，而是通过“多次探测”来处理哈希冲突，探测方式主要包括线性探测、平方探测、多次哈希等。
                    下面将主要以线性探测为例，介绍开放寻址哈希表的工作机制与代码实现。
                    1.   线性探测¶
                        线性探测采用固定步长的线性搜索来进行探测，其操作方法与普通哈希表有所不同。
                            插入元素：通过哈希函数计算桶索引，若发现桶内已有元素，则从冲突位置向后线性遍历（步长通常为 1 ），直至找到空桶，将元素插入其中。
                            查找元素：若发现哈希冲突，则使用相同步长向后线性遍历，直到找到对应元素，返回 value 即可；如果遇到空桶，说明目标元素不在哈希表中，返回 None 。

                        图 6-6 展示了开放寻址（线性探测）哈希表的键值对分布。根据此哈希函数，最后两位相同的 key 都会被映射到相同的桶。而通过线性探测，它们被依次存储在该桶以及之下的桶中。
                        然而，线性探测容易产生“聚集现象”。具体来说，数组中连续被占用的位置越长，这些连续位置发生哈希冲突的可能性越大，从而进一步促使该位置的聚堆生长，形成恶性循环，最终导致增删查改操作效率劣化。
                        值得注意的是，我们不能在开放寻址哈希表中直接删除元素。这是因为删除元素会在数组内产生一个空桶 None ，而当查询元素时，线性探测到该空桶就会返回，因此在该空桶之下的元素都无法再被访问到，程序可能误判这些元素不存在。
                        为了解决该问题，我们可以采用「懒删除 lazy deletion」机制：它不直接从哈希表中移除元素，而是利用一个常量 TOMBSTONE 来标记这个桶。在该机制下，None 和 TOMBSTONE 都代表空桶，都可以放置键值对。但不同的是，线性探测到 TOMBSTONE 时应该继续遍历，因为其之下可能还存在键值对。
                        然而，懒删除可能会加速哈希表的性能退化。这是因为每次删除操作都会产生一个删除标记，随着 TOMBSTONE 的增加，搜索时间也会增加，因为线性探测可能需要跳过多个 TOMBSTONE 才能找到目标元素。
                        为此，考虑在线性探测中记录遇到的首个 TOMBSTONE 的索引，并将搜索到的目标元素与该 TOMBSTONE 交换位置。这样做的好处是当每次查询或添加元素时，元素会被移动至距离理想位置（探测起始点）更近的桶，从而优化查询效率。
                        以下代码实现了一个包含懒删除的开放寻址（线性探测）哈希表。为了更加充分地使用哈希表的空间，我们将哈希表看作是一个“环形数组”，当越过数组尾部时，回到头部继续遍历。

                    2.  平方探测
                        平方探测与线性探测类似，都是开放寻址的常见策略之一。当发生冲突时，平方探测不是简单地跳过一个固定的步数，而是跳过“探测次数的平方”的步数，即 1,4,9,… 步。
                        平方探测通主要具有以下优势。
                            平方探测通过跳过平方的距离，试图缓解线性探测的聚集效应。
                            平方探测会跳过更大的距离来寻找空位置，有助于数据分布得更加均匀。

                        然而，平方探测也并不是完美的。
                            仍然存在聚集现象，即某些位置比其他位置更容易被占用。
                            由于平方的增长，平方探测可能不会探测整个哈希表，这意味着即使哈希表中有空桶，平方探测也可能无法访问到它。


                    3.   多次哈希
                        多次哈希使用多个哈希函数 �1(�)、�2(�)、�3(�)、… 进行探测。
                        插入元素：若哈希函数 �1(�) 出现冲突，则尝试 �2(�) ，以此类推，直到找到空桶后插入元素。
                        查找元素：在相同的哈希函数顺序下进行查找，直到找到目标元素时返回；或当遇到空桶或已尝试所有哈希函数，说明哈希表中不存在该元素，则返回 None 。
                        与线性探测相比，多次哈希方法不易产生聚集，但多个哈希函数会增加额外的计算量。

                    请注意，开放寻址（线性探测、平方探测和多次哈希）哈希表都存在“不能直接删除元素”的问题。


            编程语言的选择¶
                各个编程语言采取了不同的哈希表实现策略，以下举几个例子。
                Java 采用链式地址。自 JDK 1.8 以来，当 HashMap 内数组长度达到 64 且链表长度达到 8 时，链表会被转换为红黑树以提升查找性能。
                Python 采用开放寻址。字典 dict 使用伪随机数进行探测。
                Golang 采用链式地址。Go 规定每个桶最多存储 8 个键值对，超出容量则连接一个溢出桶。当溢出桶过多时，会执行一次特殊的等量扩容操作，以确保性能。


        哈希算法
            哈希算法的目标
                为了实现“既快又稳”的哈希表数据结构，哈希算法应包含以下特点。
                    确定性：对于相同的输入，哈希算法应始终产生相同的输出。这样才能确保哈希表是可靠的。
                    效率高：计算哈希值的过程应该足够快。计算开销越小，哈希表的实用性越高。
                    均匀分布：哈希算法应使得键值对平均分布在哈希表中。分布越平均，哈希冲突的概率就越低。

                实际上，哈希算法除了可以用于实现哈希表，还广泛应用于其他领域中。
                    密码存储：为了保护用户密码的安全，系统通常不会直接存储用户的明文密码，而是存储密码的哈希值。当用户输入密码时，系统会对输入的密码计算哈希值，然后与存储的哈希值进行比较。如果两者匹配，那么密码就被视为正确。
                    数据完整性检查：数据发送方可以计算数据的哈希值并将其一同发送；接收方可以重新计算接收到的数据的哈希值，并与接收到的哈希值进行比较。如果两者匹配，那么数据就被视为完整的。

                对于密码学的相关应用，为了防止从哈希值推导出原始密码等逆向工程，哈希算法需要具备更高等级的安全特性。
                    单向性：无法通过哈希值反推出关于输入数据的任何信息。
                    抗碰撞性：应当极其困难找到两个不同的输入，使得它们的哈希值相同。
                    雪崩效应：输入的微小变化应当导致输出的显著且不可预测的变化。

                请注意，“均匀分布”与“抗碰撞性”是两个独立的概念，满足均匀分布不一定满足抗碰撞性。例如，在随机输入 key 下，哈希函数 key % 100 可以产生均匀分布的输出。然而该哈希算法过于简单，所有后两位相等的 key 的输出都相同，因此我们可以很容易地从哈希值反推出可用的 key ，从而破解密码。

            哈希算法的设计¶
                哈希算法的设计是一个需要考虑许多因素的复杂问题。然而对于某些要求不高的场景，我们也能设计一些简单的哈希算法。
                加法哈希：对输入的每个字符的 ASCII 码进行相加，将得到的总和作为哈希值。
                乘法哈希：利用了乘法的不相关性，每轮乘以一个常数，将各个字符的 ASCII 码累积到哈希值中。
                异或哈希：将输入数据的每个元素通过异或操作累积到一个哈希值中。
                旋转哈希：将每个字符的 ASCII 码累积到一个哈希值中，每次累积之前都会对哈希值进行旋转操作。
                观察发现，每种哈希算法的最后一步都是对大质数 1000000007 取模，以确保哈希值在合适的范围内。值得思考的是，为什么要强调对质数取模，或者说对合数取模的弊端是什么？这是一个有趣的问题。
                先抛出结论：当我们使用大质数作为模数时，可以最大化地保证哈希值的均匀分布。因为质数不会与其他数字存在公约数，可以减少因取模操作而产生的周期性模式，从而避免哈希冲突。

            常见哈希算法
                不难发现，以上介绍的简单哈希算法都比较“脆弱”，远远没有达到哈希算法的设计目标。例如，由于加法和异或满足交换律，因此加法哈希和异或哈希无法区分内容相同但顺序不同的字符串，这可能会加剧哈希冲突，并引起一些安全问题。
                在实际中，我们通常会用一些标准哈希算法，例如 MD5、SHA-1、SHA-2、SHA3 等。它们可以将任意长度的输入数据映射到恒定长度的哈希值。
                近一个世纪以来，哈希算法处在不断升级与优化的过程中。一部分研究人员努力提升哈希算法的性能，另一部分研究人员和黑客则致力于寻找哈希算法的安全性问题。表 6-2 展示了在实际应用中常见的哈希算法。
                    MD5 和 SHA-1 已多次被成功攻击，因此它们被各类安全应用弃用。
                    SHA-2 系列中的 SHA-256 是最安全的哈希算法之一，仍未出现成功的攻击案例，因此常被用在各类安全应用与协议中。
                    SHA-3 相较 SHA-2 的实现开销更低、计算效率更高，但目前使用覆盖度不如 SHA-2 系列。


            数据结构的哈希值
                我们知道，哈希表的 key 可以是整数、小数或字符串等数据类型。编程语言通常会为这些数据类型提供内置的哈希算法，用于计算哈希表中的桶索引。以 Python 为例，我们可以调用 hash() 函数来计算各种数据类型的哈希值。
                整数和布尔量的哈希值就是其本身。
                浮点数和字符串的哈希值计算较为复杂，有兴趣的同学请自行学习。
                元组的哈希值是对其中每一个元素进行哈希，然后将这些哈希值组合起来，得到单一的哈希值。
                对象的哈希值基于其内存地址生成。通过重写对象的哈希方法，可实现基于内容生成哈希值。
                在许多编程语言中，只有不可变对象才可作为哈希表的 key 。假如我们将列表（动态数组）作为 key ，当列表的内容发生变化时，它的哈希值也随之改变，我们就无法在哈希表中查询到原先的 value 了。
                虽然自定义对象（比如链表节点）的成员变量是可变的，但它是可哈希的。这是因为对象的哈希值通常是基于内存地址生成的，即使对象的内容发生了变化，但它的内存地址不变，哈希值仍然是不变的。
                细心的你可能发现在不同控制台中运行程序时，输出的哈希值是不同的。这是因为 Python 解释器在每次启动时，都会为字符串哈希函数加入一个随机的盐（Salt）值。这种做法可以有效防止 HashDoS 攻击，提升哈希算法的安全性。


        Q & A
            哈希表的时间复杂度为什么不是 �(�) ？
                当哈希冲突比较严重时，哈希表的时间复杂度会退化至 �(�) 。当哈希函数设计的比较好、容量设置比较合理、冲突比较平均时，时间复杂度是 �(1) 。我们使用编程语言内置的哈希表时，通常认为时间复杂度是 �(1) 。

            为什么不使用哈希函数 �(�)=� 呢？这样就不会有冲突了
                在 �(�)=� 哈希函数下，每个元素对应唯一的桶索引，这与数组等价。然而，输入空间通常远大于输出空间（数组长度），因此哈希函数的最后一步往往是对数组长度取模。换句话说，哈希表的目标是将一个较大的状态空间映射到一个较小的空间，并提供 �(1) 的查询效率。

            哈希表底层实现是数组、链表、二叉树，但为什么效率可以比他们更高呢？
                首先，哈希表的时间效率变高，但空间效率变低了。哈希表有相当一部分的内存是未使用的，
                其次，只是在特定使用场景下时间效率变高了。如果一个功能能够在相同的时间复杂度下使用数组或链表实现，那么通常比哈希表更快。这是因为哈希函数计算需要开销，时间复杂度的常数项更大。
                最后，哈希表的时间复杂度可能发生劣化。例如在链式地址中，我们采取在链表或红黑树中执行查找操作，仍然有退化至 �(�) 时间的风险。

            多次哈希有不能直接删除元素的缺陷吗？对于标记已删除的空间，这个空间还能再次使用吗？
                多次哈希是开放寻址的一种，开放寻址法都有不能直接删除元素的缺陷，需要通过标记删除。被标记为已删除的空间是可以再次被使用的。当将新元素插入哈希表，并且通过哈希函数找到了被标记为已删除的位置时，该位置可以被新的元素使用。这样做既能保持哈希表的探测序列不变，又能保证哈希表的空间使用率。

            为什么在线性探测中，查找元素的时候会出现哈希冲突呢？
                查找的时候通过哈希函数找到对应的桶和键值对，发现 key 不匹配，这就代表有哈希冲突。因此，线性探测法会根据预先设定的步长依次向下查找，直至找到正确的键值对或无法找到跳出为止。

            为什么哈希表扩容能够缓解哈希冲突？
                哈希函数的最后一步往往是对数组长度 � 取余，让输出值落入在数组索引范围；在扩容后，数组长度 � 发生变化，而 key 对应的索引也可能发生变化。原先落在同一个桶的多个 key ，在扩容后可能会被分配到多个桶中，从而实现哈希冲突的缓解。




ACM   每日默写！！！
    你是可以写出来的 尤其是模拟题  都很简单的
    复杂度考量    1s 10^8次方
        int （2^31 10^9） long
        long 8个字节  2^63次方  有符号数  9.2*10^18
        int 类型 21亿 
        long 8个字节  2^63次方  有符号数  9.2*10^18
        复杂度

        读取这块先不优化 先实现基础功能
        通用降低时间复杂度的方法
            预处理和缓存：
                计算一次，多次使用，避免重复计算
                使用哈希表存储中间结果

            识别不变量：
                找出在不同操作间保持不变的部分

            数学分析：
                分析问题的数学属性

            空间换时间：
                使用额外的数据结构(频率表)来加速计算

            批处理思维：
                不是对每个位置独立处理，而是考虑它们与整体的关系

            问题转化：


    输入输出位数
        %d %.2f

    输入输出问题
        string=scanner.nextLine().trim();
        tokens=string.split("\\s+");正确的正则
        高效输入       BufferedReader br = new BufferedReader(new InputStreamReader(System.in));        String str = br.readLine();
        高效输出


    codeforces
    如何降时间复杂度
    var

    必备基础算法
        字符串转化成数组   Integer.parseInt函数

    洛谷
    读取图

    易错点
        不用节约变量

    容器
        list

        stack

        queue

        Map
            put 方法

        Set
            add

        Arrays  
            属性length：返回数组长度，注意不加小括号
            Arrays.sort()：数组排序
            Arrays.fill(int[] a, int val)：填充数组
            Arrays.toString()：将数组转化为字符串
            Arrays.deepToString()：将多维数组转化为字符串数组不可变长使用Arrays需要
            import java.util.Arrays



搜索题！！！
    技法
        状态标记
            搜索中 未搜索 搜索完成


    技巧
        反转元素再搜索
        哈希表O(1)搜索
            数组 、集合 、映射
            两数之和 赎金信（数组映射） 三数之和（去重逻辑）  四数之和（哈希表不好剪枝 不如双指针法）

        二分加速搜索
            有单调性一定可以二分，没有单调性可能可以二分
            二分的本质是边界，区间可以一分为二，一边满足性质，一边不满足性质
            求最小的最大，求最大的最小也常用二分
            查找某个值
            查找区间第一个值
            查找区间最后一个值
            可以寻找到上一个区间的最大值 下一个区间的最小值 加快搜索速度

        插入
            插入排序：稳定
            希尔排序

        快速排序再搜索

        归并排序再搜索
            归并排序：稳定
                数组中的逆序对
                区间和的个数在某个区间


        BFS
        DFS
        堆上搜
            数组中的第K个最大元素
            前K 个高频元素
            数据流中的中位数
            TopK问题
                第K个最大元素
                移除K位数字得到最小结果-栈
                数组中前K个高频元素
                查找和最小的K对数字

            字典序
                下一个排列
                字典序的第K小数字
                字典序排数-先序遍历
                按字典序排在最后的子串


        双指针
            数组+哈希表+双指针

        滑动窗口
        前缀和
        栈与队列
            注意事项
                stack arraydeque linkedlist

            类型
                用栈实现队列
                用队列实现栈
                单调栈
                    什么时候需要用？
                    为每个数找出满足条件的数  比如在它左边 距离最近 比它小的数

                优先队列
                    什么时候需要用？


            体型
                有效的括号：匹配问题都是栈的强项
                逆波兰表达式求值：
                    栈与递归之间在某种程度上是可以转换的，其实逆波兰表达式相当于是二叉树中的后序遍历。

                滑动窗口最大值：
                    单调栈 单调队列

                前K个高频元素：
                    优先队列（披着队列外衣的堆，需要自行定义是大顶堆还是小顶堆）

                使用一个显式的栈来模拟调用栈的行为，从而将递归转化为迭代形式
                接雨水 每日温度 ：单调栈  



    题型
        搜索旋转排序数组
        合并区间（很好的题目 需要数学和逻辑）
        螺旋数组
        轮转数组（数学角度）
            多次翻转数组

         除自身以外数组的乘积 
        缺失的第一个正数 
        矩阵置零 
        旋转矩阵（有三种方法）
        搜索二维矩阵II
        缺失的第一个正数
        删除问题
            删除排序数组中的重复项
            删除有序数组中的重复项 II：https://leetcode.cn/problems/remove-duplicates-from-sorted-array-ii



在树上搜！！！
    底层
        我们假设我们的数据量达到了亿级别，主存当中根本存储不下，我们只能以块的形式从磁盘读取数据，与主存的访问时间相比，磁盘的 I/O 操作相当耗时，而提出 B-树的主要目的就是减少磁盘的 I/O 操作。
        平衡二叉搜索树（哈希表和集合的底层实现，增删复杂度LogN）
        二叉树的存储方式
            链式存储
            顺序存储

        二叉树节点的深度：指从根节点到该节点的最长简单路径边的条数。
        二叉树节点的高度：指从该节点到叶子节点的最长简单路径边的条数。

    类型
        递归
            前序（根左右）、中序（左中右）、后序（左右中）
                涉及到二叉树的构造，无论普通二叉树还是二叉搜索树一定前序，都是先构造中节点。
                求普通二叉树的属性，一般是后序，一般要通过递归函数的返回值做计算。
                    需要对题目树的各种情况做分类判断 详细分析


            求二叉搜索树的属性，一定是中序了，要不白瞎了有序性了。

        迭代做法
            递归可以做的，栈也能做！
            前序遍历：前序遍历是中左右，每次先处理的是中间节点，那么先将根节点放入栈中，然后将右孩子加入栈，再加入左孩子，模拟栈的方法。  前序也是回溯
            中序遍历：需要借用指针的遍历来帮助访问节点，栈则用来处理节点上的元素。
            后序遍历：先序遍历是中左右，后序遍历是左右中，那么我们只需要调整一下先序遍历的代码顺序，就变成中右左的遍历顺序，然后在反转result数组，输出的结果顺序就是左右中了
            在实际项目开发的过程中我们是要尽量避免递归！因为项目代码参数、调用关系都比较复杂，不容易控制递归深度，甚至会栈溢出。

        层序
            队列实现
            二叉树的右视图
            二叉树的层平均值
            N叉树的层序遍历
                引申到图论中

            在每个树中找最大值
            填充每个节点的下一个右侧节点指针
                注意单独处理

            二叉树的最大深度
                理解深度的意思 从根节点出发

            二叉树的最小深度

        二叉树的性质
            是否对称
            最大深度
                根节点的高度就是二叉树的最大深度

            最小深度 
                求二叉树的最小深度和求二叉树的最大深度的差别主要在于处理左右孩子不为空的逻辑。

            完全二叉树节点个数
                理解深度的概念  
                利用好满二叉树的性质深度应该用前序

            是否平衡
            二叉树的所有路径
                递归+回溯 

            路径总和
            左叶子之和！！
                不要找错左叶子  遍历的时候 要明确好条件

            找树左下角的值
                在搜索中可以保证优先最左搜索，从而保证结果的准确性
                修改递归代码的顺序

            路径总和
                回溯


        二叉树的改造
            自身性质

            翻转二叉树
                理解翻转其实就是交换 进入之前交换和离开交换都可以 中序遍历不太方便

            对称二叉树
                是要遍历左右子树 所以需要后序的返回结果

            构造二叉树
                从中序与后序遍历序列构造二叉树
                从前序与中序遍历序列构造二叉树
                最大二叉树

            合并二叉树

        二叉搜索树的性质
            构建一棵二叉搜索树    利用二叉进行剪枝
            二叉搜索树中的搜索
                利用中序遍历

            验证二叉搜索树
            二叉树上应该怎么求，二叉搜索树上又应该怎么求？？？？
            二叉搜索树的最小绝对差
            二叉搜索树中第K小的数
            二叉搜索树中的众数
            二叉树的最近公共祖先
                最近公共祖先表示为一个结点 x，满足 x 是 p、q 的祖先且 x 的深度尽可能大（一个节点也可以是它自己的祖先）。
                分类讨论
                求最小公共祖先，需要从底向上遍历，那么二叉树，只能通过后序遍历（即：回溯）实现从底向上的遍历方式。

            二叉搜索树的最近公共祖先
                利用性质 ，从上往下遍历

            验证平衡二叉树
                求深度适合用前序遍历，而求高度适合用后序遍历。


        二叉搜索树的操作
            二叉搜索树中的插入操作
                按照二叉搜索树的顺序去遍历

            难题就是构建一棵二叉搜素树
            删除二叉搜索树中的节点
                涉及到二叉搜索树的结构调整

            修建二叉搜索树
                如果不对递归有深刻的理解，本题有点难 单纯移除一个节点那还不够，要修剪！

            将有序数组转换为二叉搜索树
                构造二叉搜索树一不小心就平衡了

            把二叉搜索树转化为累加树



在图上搜！！！
    例如：通信网络（拓扑排序、最短路算法），社交网络（深搜、广搜），路径优化（最短路算法），任务调度（拓扑排序），生物信息学（基因为节点，基因关系为边），游戏开发（A * 算法等）等等深搜与广搜并查集最小生成树拓扑排序最短路算法
    拓扑排序
    迪杰斯特拉找最短路
    图的输入 存储
        二维矩阵
        邻接表

    广度优先搜索
        可以搜索到最短路径

    深度优先搜索
    类型
        岛屿数量 
        腐烂的水果

    所有可达路径
    岛屿的最大面积
    孤岛的总面积
    沉没孤岛
    水流问题
    建造最大工岛
    字符串接龙
    有向图的完全可达性
    岛屿的周长
    寻找存在的路径
    冗余连接
    冗余连接1
    最小生成树之prim
    最小生成树之Kruskal
    拓扑排序
    dijkstra朴素版
    diikstra堆优化版
    Bellman ford算法
    SPFA算法
    Bellman_ford之判断负权回路
    Bellman ford之单源有限最短路
    Floyd算法
    A*算法

在链表上搜！！！
    注意事项
        避免进入死循环
        尤其注意首尾链表是否正确处理
        注意是否需要原地修改
        想清楚修改的逻辑    先确定新指针 再修改旧指针

    链表题技巧
        虚拟头节点
            当头结点可能会变动的时候需要加虚拟头节点 dummy = ListNode(0,head);

        双指针
            快慢指针
            前后指针

        迭代
            多用指针 表示一个链表节点的前中后
            注意不要陷入死循环

        递归

    链表题类型
        链表的操作
            寻找链表的中点
            翻转链表
            删除链表重复元素II
            反转链表
            链表的复制
            链表转化为数组
            两两交换链表中的节点
            随机链表的复制
            排序链表
                归并排序
                合并两个有序链表
                合并K个升序链表


        链表的性质
            性质题往往通过对链表的操作来分析性质
            回文链表
            环形链表
            链表的中点
            LRU缓存
                LRU缓存（哈希表和双向链表 分析哈希数据结构的原理加分析 java 源码是什么）
                哈希链表 LinkedHashMap
                双向链表+哈希表

            LFU 缓存
                淘汰策略淘汰使用次数最少的
                更难
                哈希链表实现


        链表的种类
            单向链表
            回文链表
            双向链表



在数组上搜！！
    字符数组   KMP 双指针搜索
        https://blog.csdn.net/yzhcjl_/article/details/127728717
        是若干字符组成的有限序列，也可以理解为是一个字符数组
        双指针法：双指针法在数组，链表和字符串中很常用。
        反转系列：考察的是对代码的掌控能力。可以先整体反转再局部反转
        填充类题：先预先给数组扩容带填充后的大小，然后在从后向前进行操作。降低算法复杂度的好方法。
        KMP:当出现字符串不匹配时，可以知道一部分之前已经匹配的文本内容，可以利用这些信息避免从头再去做匹配了。精髓所在就是前缀表。起始位置到下标i之前（包括i）的子串中，有多大长度的相同前缀后缀。
        KMP的主要思想是当出现字符串不匹配时，可以知道一部分之前已经匹配的文本内容，可以利用这些信息避免从头再去做匹配了。
        KMP 算法的关键是利用模式串的前缀和后缀信息构建 next 数组，用于在失配时跳过不必要的比较。模式串是 "abaabc"，长度为 6。我们从左到右计算 next 数组：
        所以如何记录已经匹配的文本内容，是KMP的重点，也是next数组肩负的重任。
        前缀表是用来回退的，它记录了模式串与主串(文本串)不匹配的时候，模式串应该从哪里开始重新匹配。
        整个KMP算法的时间复杂度是O(n+m)的。
            next数组既可以就是前缀表，也可以是前缀表统一减一（右移一位，初始位置为-1）

        好题：
        翻转字符串里的单词（StringBuilder） 
        右旋转字符串
        实现 strStr()
        重复的子字符串

    模式匹配
        单模式单匹配：KMP
        多模式单匹配：Trie
        多模式多匹配：AC自动机


用回溯搜索！！
    组合问题：N个数里面按一定规则找出k个数的集合
        组合
         括号生成（每个位置选或者不选 符合规则）
        分割回文串 （分割问题也是组合问题 选了部分之后 接下来怎么做  切割线就是组合的过程）
        复原ip地址（）

    切割问题：一个字符串按一定规则有几种切割方式

    子集问题： （每个元素都可以选或者不选  无序）一个N个数的集合里有多少符合条件的子集
        子集（组合问题和分割问题都是收集树的叶子节点，而子集问题是找树的所有节点！）
        电话号码的字母组合
        组合总和（选或不选的逻辑 或者从答案出发 用枚举的逻辑做 记录每一次枚举的结果）
        子集ii
        递增子序列(和子集问题有点像，但又处处是陷阱)
        重新安排行程

    排列问题：（所有的元素都要选 有序 用数组来记录可以选哪些数字） N个数按一定规则全排列，有几种排列方式
        全排列  （使用数组来记录选择）
        N皇后
        解数独

    棋盘问题：N皇后，解数独等等

用dp 搜！！！
    状态
    是什么
        动态规划中每一个状态一定是由上一个状态推导出来的，这一点就区分于贪心，贪心没有状态推导，而是从局部直接选最优的，
        贪心解决不了动态规划的问题
        动态规划的优化是必考

    注意事项
        dp数组初始化
        确定遍历顺序
        做动态规划的题目，最好的过程就是自己在纸上举一个例子把对应的dp数组的数值推导一下，然后在动手写代码！
        明确定义状态：确保状态定义清晰，理解每个dp[i]或dp[i][j]代表的具体含义。
        找准状态转移方程：这是解题的核心，需要思考当前状态与之前状态的关系。
        初始化基础状态：正确设置初始条件，比如dp[0]或dp[0][0]的值。
        注意遍历顺序：有些问题需要特定的遍历顺序（如从左到右或从右到左）。
        处理边界情况：考虑数组为空、只有一个元素等特殊情况。
        空间优化：许多二维DP问题可以优化为一维，节省空间。
        避免数组越界：特别是在状态转移时，确保引用的索引在有效范围内。
        数据类型溢出：对于可能产生大数的问题，注意使用合适的数据类型。
        子问题重叠：确保已解决的子问题不会重复计算。
        记忆化搜索：有时自顶向下的记忆化搜索比自底向上的动态规划更直观。

    类型
        求最大 求最值 求方案数量
            最大子数组
                dp[i]表示以nums[i]为结尾的最大子数组和

            乘积最大的子数组
            最长递增子序列（LIS问题）
                 动态规划，时间复杂度O(n²)
                二分  蜘蛛纸牌
                贪心+二分  优化到O(n log n)
                贪心策略：维护一个数组 tails，其中 tails[i] 表示长度为 i+1 的递增子序列的最小末尾元素。通过尽可能小的末尾元素，为后续元素提供更大的扩展空间。
                二分查找：对于每个元素，使用二分查找确定其在 tails 中的位置，若该元素大于 tails 的所有元素，则扩展序列长度；否则替换 tails 中第一个不小于它的元素，保证 tails 数组的递增性。这个方法重点在与证明

            最长公共子序列（LCS问题）可以不连续
                两个字符串或序列的最长公共子序列，不要求连续。例如，"abcde"和"ace"的LCS是"ace"，长度3。通常用二维动态规划解决，时间复杂度O(mn)。
                穷举+剪枝
                子序列问题十有八九要用动态规划
                明确Dp数组的含义
                定义base case
                找状态转移方程


            最长回文子序列
                子序列问题就是要难一点，因为穷举都不好穷举

            最长连续递增序列
                比如数组中的连续元素组成的递增序列，要求元素连续。例如，[1,3,5,4,7]中的最长连续递增序列是[1,3,5]，长度3。这个可以用一次遍历，记录当前长度和最大长度即可，O(n)时间。

            最长连续序列
                例如数组[100,4,200,1,3,2]，最长连续序列是[1,2,3,4]，长度4。这个通常用哈希集合存储所有元素，然后对于每个元素，检查是否有前驱，如果没有，则向后找连续的元素，记录长度。时间复杂度O(n)。

            编辑距离
                比较实用的算法动态规划就是在找状态和选择涉及两个子串涉及到一些递归的方法

            最长回文子串  
                连续的！！！！！！给你一个字符串 s，找到 s 中最长的回文子串。枚举子串长度然后再从i=0,=子串长度+i-开始枚举  时间复杂度 On^2 空间复杂度 ON^2 中心扩展算法  时间复杂度 On^2 空间复杂度 O1所有的状态在转移的时候的可能性都是唯一的。也就是说，我们可以从每一种边界情况开始「扩展」，也可以得出所有的状态对应的答案。我们枚举所有的「回文中心」并尝试「扩展」，直到无法扩展为止，此时的回文串长度即为此「回文中心」下的最长回文串长度。我们对所有的长度求出最大值，即可得到最终的答案。Manacher算法 O（n）  臂长臂长，表示中心扩展算法向外扩展的长度。如果一个位置的最大回文字符串长度为 2 * length + 1 ，其臂长为 length。

            最大子序和

        背包问题
            0-1背包问题
                有n件物品和一个最多能背重量为w 的背包。第i件物品的重量是weight[i]，得到的价值是value[i]   每件物品只能用一次，求解将哪些物品装入背包里物品价值总和最大。

            完全背包问题
                零钱兑换 无限选取
                关于完全背包，有两种写法，一种是外层循环枚举物品，内层循环枚举体积；另一种是外层循环枚举体积，内层循环枚举物品。如何评价这两种写法的优劣？
                答：两种写法都可以，但更推荐前者。外层循环枚举物品的写法，只会遍历物品数组一次；而内层循环枚举物品的写法，会遍历物品数组多次。从 cache 的角度分析，多次遍历数组会导致额外的 cache miss，带来额外的开销。所以虽然这两种写法的时间空间复杂度是一样的，但外层循环枚举物品的写法常数更小。

            二维dp数组01背包，先遍历物品还是先遍历背包都是可以的，且第二层for循环是从小到大遍历
                dp[i][j] 表示从下标为 [0 - i] 的物品里任意取，放进容量为j的背包，价值总和最大是多少。

            一维dp数组01背包，只能先遍历物品再遍历背包容量，且第二层for循环是从大到小遍历。
            求组合数：外层遍历物品，内层遍历背包
            求排列数：外层遍历背包，内层遍历物品
            求最小数：两层for循环的先后顺序无所谓
            1. 问能否能装满背包（或者最多装多少）：
            	dp[j] = max(dp[j], dp[j - nums[i]] + nums[i])
            2. 问装满背包有几种方法：
            	dp[j] += dp[j - nums[i]]
            3. 问背包装满最大价值：
            	dp[j] = max(dp[j], dp[j - weight[i]] + value[i])
            4. 问装满背包所有物品的最小个数：
            	dp[j] = min(dp[j], dp[j - coins[i]] + 1)

        一维
            爬楼梯

        二维
        树形dp

        数位DP（数位动态规划）
            数位动态规划（数位DP）主要用于解决“在区间[l,r]这个范围内，满足某种约束的数字的数量、总和、平方“这一类问题
            圈子内针对这类问题，有两类写法，一种是记忆化搜索写法，一种是迭代写法。笔者两种写法都尝试过一段时间，力推记忆化搜索写法，也立志灭绝所有迭代写法（划掉）
            记搜写法容易举一反三、易编码
            预处理后的迭代写法，往往边界条件很多，状态转移方程容易写错或漏项，其边界容易漏判误判；且不同题目时，迭代写法的DP过程变化较大，而记搜的dfs框架则非常套路，容易举一反三。
            带来的好处就是，在ACM区域赛、NOIP现场比赛，迭代写法可能就需要调很久（可能还不容易调出来），而采用记搜占用机时较少，可以留给队友更多的时间写其他题。
            虽然不可否认的时，一定意义上，迭代写法一定意义对理解迭代的dp状态转移的思想，有一定帮助。
            小欧字符串  oppo



用贪心搜！！！
    每一步求局部最优解
        靠自己手动模拟，如果模拟可行，就可以试一试贪心策略，如果不可行，可能需要动态规划。
        最好用的策略就是举反例，如果想不到反例，那么就试一试贪心吧。
        因为贪心有时候就是常识性的推导，所以会认为本应该就这么做！
        设计的贪心策略很多时候只是“部分正确”的，会过不了一些测试用例。
        贪心模板：想清楚局部最优是什么！！！
        证明贪心


    题型
        跳跃游戏
        分发饼干
        摆动序列
        最大子序和
        买卖股票的最佳时机
        K次取反后最大化的数组和
        加油站
        分发糖果
        柠檬水找零
        根据身高重建队列
        根据身高重建队列(vector原理讲解)
        用最少数量的箭引爆气球
        无重叠区间
        划分字母区间
        合并区间
        单调递增的数字
        监控二叉树


其他类型
    字典树
        二十六叉树
        trie树
            快速存储和查找字符串集合 又称为字典树


    数论题
        基础运算
            位运算
            快速幂

        质数
            我们可以得知常见的质数有 2、3、5 等
            质数判定
                试除法

            质数筛选

            质因数分解

            互质判定
                gcd



        快速幂算法

        容斥原理

        组合数学题
            恰好有 k 个 1 的子数组数量 = 至多有 k 个 1 的子数组数量 - 至多有 k−1 个 1 的子数组数量。
            题主说的10^x+7多半时候是1e9+7吧。
            模一个大数和模一个质数可以减少冲突。
            比如说如果所有的结果都是偶数…你模6就只可能出现0, 2, 4这三种情况…但模5还是可以出现2, 4, 1, 3这四(4=5-1)种情况的…
            hash表如果是用取模的方法也要模一个大质数来减少冲突，出题人也会这样来 希望减少你“蒙对“的概率。
            而模1e9+7又有一个很好的特点，就是相加不爆int，相乘不爆long long。


    并查集
        路径压缩优化：在查询(find)过程中，让树的结构更加扁平化，大大提升了查询和合并的效率。
        并查集的平均复杂度为O(log2N)O(log2N)，性能优秀。
        并查集特别适用于以下场景：
            判断两个元素是否属于同一集合或群组（如好友关系、网络连接性等）。
            动态计算图中联通块数量。
            快速实现“分组”操作，如“好友圈”问题。


     字符与整数的联系——ASCII码
        每个常用字符都对应一个-128 ~ 127的数字，二者之间可以相互转化。注意：目前负数没有与之对应的字符。 import java.util.Arrays; public class Main {    public static void main(String[] args) {        char c = 'a';        System.out.println((int)c);         int a = 66;        System.out.println((char)a);    }}常用ASCII值：'A'- 'Z'是65 ~ 90，'a' - 'z'是97 - 122，0 - 9是 48 - 57。字符可以参与运算，运算时会将其当做整数：


